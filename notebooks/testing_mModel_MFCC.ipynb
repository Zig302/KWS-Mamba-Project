{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "El4Y4HcjYsEi",
        "outputId": "e8de3aaf-e304-4508-f928-c901966ab411"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets==2.16.0\n",
            "  Downloading datasets-2.16.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets==2.16.0) (3.19.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets==2.16.0) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.16.0) (18.1.0)\n",
            "Collecting pyarrow-hotfix (from datasets==2.16.0)\n",
            "  Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets==2.16.0)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==2.16.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.16.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from datasets==2.16.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==2.16.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets==2.16.0) (0.70.16)\n",
            "Collecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.16.0)\n",
            "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets==2.16.0) (3.12.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.12/dist-packages (from datasets==2.16.0) (0.34.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==2.16.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets==2.16.0) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.16.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.16.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.16.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.16.0) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.16.0) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.16.0) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.16.0) (1.20.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.4->datasets==2.16.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.4->datasets==2.16.0) (1.1.9)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.16.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.16.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.16.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.16.0) (2025.8.3)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets==2.16.0)\n",
            "  Downloading multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\n",
            "  Downloading multiprocess-0.70.17-py312-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading multiprocess-0.70.15-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.16.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.16.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.16.0) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.16.0) (1.17.0)\n",
            "Downloading datasets-2.16.0-py3-none-any.whl (507 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.15-py311-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\n",
            "Installing collected packages: pyarrow-hotfix, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.8\n",
            "    Uninstalling dill-0.3.8:\n",
            "      Successfully uninstalled dill-0.3.8\n",
            "  Attempting uninstall: multiprocess\n",
            "    Found existing installation: multiprocess 0.70.16\n",
            "    Uninstalling multiprocess-0.70.16:\n",
            "      Successfully uninstalled multiprocess-0.70.16\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.16.0 dill-0.3.7 fsspec-2023.10.0 multiprocess-0.70.15 pyarrow-hotfix-0.7\n",
            "Collecting huggingface-hub==0.20.0\n",
            "  Downloading huggingface_hub-0.20.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.20.0) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.20.0) (2023.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.20.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.20.0) (4.67.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.20.0) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.20.0) (4.15.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.20.0) (25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub==0.20.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub==0.20.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub==0.20.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub==0.20.0) (2025.8.3)\n",
            "Downloading huggingface_hub-0.20.0-py3-none-any.whl (329 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m329.1/329.1 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: huggingface-hub\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.34.4\n",
            "    Uninstalling huggingface-hub-0.34.4:\n",
            "      Successfully uninstalled huggingface-hub-0.34.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.17.1 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.20.0 which is incompatible.\n",
            "transformers 4.56.1 requires huggingface-hub<1.0,>=0.34.0, but you have huggingface-hub 0.20.0 which is incompatible.\n",
            "accelerate 1.10.1 requires huggingface_hub>=0.21.0, but you have huggingface-hub 0.20.0 which is incompatible.\n",
            "gradio 5.44.1 requires huggingface-hub<1.0,>=0.33.5, but you have huggingface-hub 0.20.0 which is incompatible.\n",
            "diffusers 0.35.1 requires huggingface-hub>=0.34.0, but you have huggingface-hub 0.20.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.20.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libao-common libao4 libid3tag0 libmad0 libopencore-amrnb0 libopencore-amrwb0\n",
            "  libsox-fmt-all libsox-fmt-alsa libsox-fmt-ao libsox-fmt-base libsox-fmt-mp3\n",
            "  libsox-fmt-oss libsox-fmt-pulse libsox3 libwavpack1\n",
            "Suggested packages:\n",
            "  libaudio2 libsndio6.1\n",
            "The following NEW packages will be installed:\n",
            "  libao-common libao4 libid3tag0 libmad0 libopencore-amrnb0 libopencore-amrwb0\n",
            "  libsox-dev libsox-fmt-all libsox-fmt-alsa libsox-fmt-ao libsox-fmt-base\n",
            "  libsox-fmt-mp3 libsox-fmt-oss libsox-fmt-pulse libsox3 libwavpack1\n",
            "0 upgraded, 16 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 1,053 kB of archives.\n",
            "After this operation, 4,061 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libao-common all 1.2.2+20180113-1.1ubuntu3 [6,568 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libao4 amd64 1.2.2+20180113-1.1ubuntu3 [35.2 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libid3tag0 amd64 0.15.1b-14 [31.3 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmad0 amd64 0.15.1b-10ubuntu1 [63.1 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopencore-amrnb0 amd64 0.1.5-1 [94.8 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopencore-amrwb0 amd64 0.1.5-1 [49.1 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox3 amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [240 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-alsa amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [11.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-ao amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [7,740 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwavpack1 amd64 5.4.0-1build2 [83.7 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-base amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [33.7 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-mp3 amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [17.3 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-oss amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [9,424 B]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-pulse amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [7,732 B]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-all amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [5,016 B]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-dev amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [356 kB]\n",
            "Fetched 1,053 kB in 2s (534 kB/s)\n",
            "Selecting previously unselected package libao-common.\n",
            "(Reading database ... 126374 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libao-common_1.2.2+20180113-1.1ubuntu3_all.deb ...\n",
            "Unpacking libao-common (1.2.2+20180113-1.1ubuntu3) ...\n",
            "Selecting previously unselected package libao4:amd64.\n",
            "Preparing to unpack .../01-libao4_1.2.2+20180113-1.1ubuntu3_amd64.deb ...\n",
            "Unpacking libao4:amd64 (1.2.2+20180113-1.1ubuntu3) ...\n",
            "Selecting previously unselected package libid3tag0:amd64.\n",
            "Preparing to unpack .../02-libid3tag0_0.15.1b-14_amd64.deb ...\n",
            "Unpacking libid3tag0:amd64 (0.15.1b-14) ...\n",
            "Selecting previously unselected package libmad0:amd64.\n",
            "Preparing to unpack .../03-libmad0_0.15.1b-10ubuntu1_amd64.deb ...\n",
            "Unpacking libmad0:amd64 (0.15.1b-10ubuntu1) ...\n",
            "Selecting previously unselected package libopencore-amrnb0:amd64.\n",
            "Preparing to unpack .../04-libopencore-amrnb0_0.1.5-1_amd64.deb ...\n",
            "Unpacking libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
            "Selecting previously unselected package libopencore-amrwb0:amd64.\n",
            "Preparing to unpack .../05-libopencore-amrwb0_0.1.5-1_amd64.deb ...\n",
            "Unpacking libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
            "Selecting previously unselected package libsox3:amd64.\n",
            "Preparing to unpack .../06-libsox3_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-alsa:amd64.\n",
            "Preparing to unpack .../07-libsox-fmt-alsa_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-ao:amd64.\n",
            "Preparing to unpack .../08-libsox-fmt-ao_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-ao:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libwavpack1:amd64.\n",
            "Preparing to unpack .../09-libwavpack1_5.4.0-1build2_amd64.deb ...\n",
            "Unpacking libwavpack1:amd64 (5.4.0-1build2) ...\n",
            "Selecting previously unselected package libsox-fmt-base:amd64.\n",
            "Preparing to unpack .../10-libsox-fmt-base_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-mp3:amd64.\n",
            "Preparing to unpack .../11-libsox-fmt-mp3_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-mp3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-oss:amd64.\n",
            "Preparing to unpack .../12-libsox-fmt-oss_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-oss:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-pulse:amd64.\n",
            "Preparing to unpack .../13-libsox-fmt-pulse_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-pulse:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-all:amd64.\n",
            "Preparing to unpack .../14-libsox-fmt-all_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-all:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-dev:amd64.\n",
            "Preparing to unpack .../15-libsox-dev_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-dev:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-oss:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libao-common (1.2.2+20180113-1.1ubuntu3) ...\n",
            "Setting up libid3tag0:amd64 (0.15.1b-14) ...\n",
            "Setting up libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
            "Setting up libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libao4:amd64 (1.2.2+20180113-1.1ubuntu3) ...\n",
            "Setting up libmad0:amd64 (0.15.1b-10ubuntu1) ...\n",
            "Setting up libwavpack1:amd64 (5.4.0-1build2) ...\n",
            "Setting up libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
            "Setting up libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-ao:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-mp3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-pulse:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-all:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-dev:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch==2.4.0\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.4.0%2Bcu121-cp312-cp312-linux_x86_64.whl (799.0 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m799.0/799.0 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.19.0\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.19.0%2Bcu121-cp312-cp312-linux_x86_64.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m128.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.4.0\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.4.0%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m113.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (2023.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (75.2.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m121.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.0.0 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.0.0-1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.5 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.19.0) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.19.0) (11.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.4.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0+cu126\n",
            "    Uninstalling torch-2.8.0+cu126:\n",
            "      Successfully uninstalled torch-2.8.0+cu126\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.23.0+cu126\n",
            "    Uninstalling torchvision-0.23.0+cu126:\n",
            "      Successfully uninstalled torchvision-0.23.0+cu126\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.8.0+cu126\n",
            "    Uninstalling torchaudio-2.8.0+cu126:\n",
            "      Successfully uninstalled torchaudio-2.8.0+cu126\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.17.1 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.20.0 which is incompatible.\n",
            "accelerate 1.10.1 requires huggingface_hub>=0.21.0, but you have huggingface-hub 0.20.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.0+cu121 torchaudio-2.4.0+cu121 torchvision-0.19.0+cu121 triton-3.0.0\n",
            "Collecting causal-conv1d==1.4.0\n",
            "  Downloading causal_conv1d-1.4.0.tar.gz (9.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mamba-ssm==2.2.2\n",
            "  Downloading mamba_ssm-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from causal-conv1d==1.4.0) (2.4.0+cu121)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from causal-conv1d==1.4.0) (25.0)\n",
            "Collecting ninja (from causal-conv1d==1.4.0)\n",
            "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from mamba-ssm==2.2.2) (0.8.1)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.12/dist-packages (from mamba-ssm==2.2.2) (3.0.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from mamba-ssm==2.2.2) (4.56.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.74.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.9)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (2023.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->causal-conv1d==1.4.0) (12.6.85)\n",
            "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers->mamba-ssm==2.2.2)\n",
            "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers->mamba-ssm==2.2.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->mamba-ssm==2.2.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers->mamba-ssm==2.2.2) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->mamba-ssm==2.2.2) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->mamba-ssm==2.2.2) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers->mamba-ssm==2.2.2) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers->mamba-ssm==2.2.2) (1.1.9)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->mamba-ssm==2.2.2) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->mamba-ssm==2.2.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->mamba-ssm==2.2.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->mamba-ssm==2.2.2) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch->causal-conv1d==1.4.0) (1.3.0)\n",
            "Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: causal-conv1d, mamba-ssm\n",
            "  Building wheel for causal-conv1d (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for causal-conv1d: filename=causal_conv1d-1.4.0-cp312-cp312-linux_x86_64.whl size=104884589 sha256=70c6d91d00c625d750b83c9c4bdd0bd395c61aff9baa8c0d58e0a33dabbe3b4e\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/bd/04/a4893fd5ad69a02f55b49f04dc1dbbd7c439332db7895f62ff\n",
            "  Building wheel for mamba-ssm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mamba-ssm: filename=mamba_ssm-2.2.2-cp312-cp312-linux_x86_64.whl size=324005633 sha256=f4cf06585ac28c783dbe6fe357c64218415af3665c3c06106be8f86dab69b2a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/b8/99/4112d82fe2a9458dd194c3ff54c43a14a8594c8f90cf16046f\n",
            "Successfully built causal-conv1d mamba-ssm\n",
            "Installing collected packages: ninja, huggingface-hub, causal-conv1d, mamba-ssm\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.0\n",
            "    Uninstalling huggingface-hub-0.20.0:\n",
            "      Successfully uninstalled huggingface-hub-0.20.0\n",
            "Successfully installed causal-conv1d-1.4.0 huggingface-hub-0.34.4 mamba-ssm-2.2.2 ninja-1.13.0\n"
          ]
        }
      ],
      "source": [
        "# --- Environment & installs ---\n",
        "!pip install datasets==2.16.0\n",
        "!pip install huggingface-hub==0.20.0\n",
        "!apt-get install -y libsox-dev\n",
        "!pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install causal-conv1d==1.4.0 mamba-ssm==2.2.2 scikit-learn tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Keyword-Spotting (Google Speech Commands v0.02) with Mamba\n",
        "# Front-end: MFCC (F=40) -> Linear(40 -> d_model) -> Mamba * L -> Classifier\n",
        "# =========================================================\n",
        "\n",
        "from __future__ import annotations\n",
        "import json, os, random, math, time\n",
        "from pathlib import Path\n",
        "from typing import Tuple, Dict, List\n",
        "\n",
        "import torch, torchaudio\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchaudio.transforms as T\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from datasets import load_dataset\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from mamba_ssm import Mamba\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 0) Repro & device\n",
        "# ---------------------------------------------------------\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "use_amp = (device.type == \"cuda\")\n",
        "set_seed(42)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2e2XEsxrbNBl",
        "outputId": "30d08c53-1682-4f82-979b-a88bf78e8b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:163: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd\n",
            "/usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:239: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @custom_bwd\n",
            "/usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:985: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd\n",
            "/usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @custom_bwd\n",
            "/usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:25: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd\n",
            "/usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:61: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @custom_bwd\n",
            "/usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:757: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd\n",
            "/usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:835: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @custom_bwd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# 1) Waveform-level augmentation (shift + noise)\n",
        "# ---------------------------------------------------------\n",
        "class Augment:\n",
        "    def __init__(self,\n",
        "                 stretch: Tuple[float,float]=(1.0,1.0),\n",
        "                 shift_ms: int = 100,\n",
        "                 noise: Tuple[float,float]=(0.,0.05),\n",
        "                 sr: int = 16_000):\n",
        "        self.stretch = stretch\n",
        "        self.shift   = int(shift_ms * sr / 1000)\n",
        "        self.noise   = noise\n",
        "        self.sr      = sr\n",
        "\n",
        "    def _shift(self, x: torch.Tensor):\n",
        "        if self.shift == 0:\n",
        "            return x\n",
        "        s = int(torch.randint(-self.shift, self.shift + 1, ()).item())\n",
        "        if s == 0:\n",
        "            return x\n",
        "        return (F.pad(x, (s, 0))[:, :-s] if s > 0 else F.pad(x, (0, -s))[:, -s:])\n",
        "\n",
        "    def __call__(self, wav: torch.Tensor):\n",
        "        squeezed = False\n",
        "        if wav.dim() == 1:\n",
        "            wav = wav.unsqueeze(0)\n",
        "            squeezed = True\n",
        "        if self.stretch != (1.0, 1.0):\n",
        "            factor = float(torch.empty(()).uniform_(*self.stretch))\n",
        "            if abs(factor - 1.0) > 1e-3:\n",
        "                wav, _ = torchaudio.sox_effects.apply_effects_tensor(\n",
        "                    wav, self.sr, [[\"tempo\", f\"{factor}\"]]\n",
        "                )\n",
        "        wav = self._shift(wav)\n",
        "        if self.noise[1] > 0:\n",
        "            sigma = float(torch.empty(()).uniform_(*self.noise))\n",
        "            if sigma > 0:\n",
        "                wav = wav + sigma * torch.randn_like(wav)\n",
        "        return wav.squeeze(0) if squeezed else wav\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2) Front-end: MFCC or Mel with SpecAug AFTER log (if mel)\n",
        "#    For MFCC we mask on the MFCCs (computed from log-mel internally).\n",
        "# ---------------------------------------------------------\n",
        "class WaveToSpec:\n",
        "    def __init__(self,\n",
        "                 feature_type: str = \"mfcc\",     # \"mfcc\" or \"mel\"\n",
        "                 sample_rate: int = 16_000,\n",
        "                 n_fft: int = 2048,\n",
        "                 hop_length: int = 256,\n",
        "                 n_mels: int = 128,\n",
        "                 n_mfcc: int = 40,\n",
        "                 top_db: int | None = 80,\n",
        "                 apply_mask: bool = True,\n",
        "                 freq_mask_param: int = 3,\n",
        "                 time_mask_param: int = 12):\n",
        "        self.feature_type = feature_type.lower(); assert self.feature_type in {\"mel\",\"mfcc\"}\n",
        "        self.apply_mask = apply_mask\n",
        "\n",
        "        if self.feature_type == \"mel\":\n",
        "            self.spec = T.MelSpectrogram(sample_rate, n_fft=n_fft, hop_length=hop_length,\n",
        "                                         n_mels=n_mels, power=2.0)\n",
        "            self.to_db = T.AmplitudeToDB(stype=\"power\", top_db=top_db)\n",
        "            self.freq_mask = T.FrequencyMasking(freq_mask_param) if apply_mask else None\n",
        "            self.time_mask = T.TimeMasking(time_mask_param) if apply_mask else None\n",
        "            self.n_out = n_mels\n",
        "        else:\n",
        "            self.spec = T.MFCC(sample_rate, n_mfcc=n_mfcc,\n",
        "                                melkwargs=dict(n_fft=n_fft, hop_length=hop_length, n_mels=n_mels))\n",
        "            # MFCC branch does not use AmplitudeToDB directly; MFCC uses log-mel inside.\n",
        "            self.to_db = None\n",
        "            self.freq_mask = T.FrequencyMasking(freq_mask_param) if apply_mask else None\n",
        "            self.time_mask = T.TimeMasking(time_mask_param) if apply_mask else None\n",
        "            self.n_out = n_mfcc\n",
        "\n",
        "    def __call__(self, wav: torch.Tensor) -> torch.Tensor:\n",
        "        if wav.dim() == 1:\n",
        "            wav = wav.unsqueeze(0)            # [1, T]\n",
        "        feats = self.spec(wav)                # mel: [1, M, T], mfcc: [1, C, T]\n",
        "\n",
        "        if self.feature_type == \"mel\":\n",
        "            feats = self.to_db(feats.clamp(min=1e-10))  # --- LOG ---\n",
        "            if self.apply_mask:\n",
        "                feats = self.freq_mask(feats)\n",
        "                feats = self.time_mask(feats)\n",
        "        else:\n",
        "            # MFCC path: apply masks on MFCCs (post log-mel inside MFCC)\n",
        "            if self.apply_mask:\n",
        "                feats = self.freq_mask(feats)\n",
        "                feats = self.freq_mask(feats)\n",
        "                feats = self.time_mask(feats)\n",
        "                feats = self.time_mask(feats)\n",
        "\n",
        "        return feats                           # [1, F, T]"
      ],
      "metadata": {
        "id": "qZPmhsTvbPSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# 3) Dataset wrapper with dataset-level normalization\n",
        "# ---------------------------------------------------------\n",
        "class SpeechCommands(Dataset):\n",
        "    def __init__(self, hf_split, aug: Augment | None, frontend: WaveToSpec,\n",
        "                 wav_len: int = 16_000, mean: float = 0.0, std: float = 1.0):\n",
        "        self.ds, self.aug, self.front = hf_split, aug, frontend\n",
        "        self.wav_len = wav_len\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ds)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.ds[idx]\n",
        "        wav = torch.from_numpy(sample[\"audio\"][\"array\"]).float()\n",
        "\n",
        "        if wav.numel() < self.wav_len:\n",
        "            wav = F.pad(wav, (0, self.wav_len - wav.numel()))\n",
        "        else:\n",
        "            wav = wav[: self.wav_len]\n",
        "\n",
        "        if self.aug:\n",
        "            wav = self.aug(wav)\n",
        "\n",
        "        feats = self.front(wav)                              # [1, F, T]\n",
        "        feats = (feats - self.mean) / (self.std + 1e-6)      # normalize\n",
        "        feats = feats.squeeze(0).transpose(0, 1)             # [T, F]\n",
        "        return feats, sample[\"label\"]"
      ],
      "metadata": {
        "id": "Ow_00c2lbQku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# 4) Helper functions + stats\n",
        "# ---------------------------------------------------------\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_fn(batch):\n",
        "    feats, lbls = zip(*batch)\n",
        "    lens = torch.tensor([f.size(0) for f in feats], dtype=torch.long)\n",
        "    feats_padded = pad_sequence(feats, batch_first=True, padding_value=0.0)  # [B, T_max, F]\n",
        "    return feats_padded, torch.tensor(lbls), lens\n",
        "\n",
        "@torch.no_grad()\n",
        "def compute_dataset_stats(ds, frontend, wav_len=16_000):\n",
        "    feats_all = []\n",
        "    for sample in ds:\n",
        "        wav = torch.from_numpy(sample[\"audio\"][\"array\"]).float()\n",
        "        if wav.numel() < wav_len:\n",
        "            wav = F.pad(wav, (0, wav_len - wav.numel()))\n",
        "        else:\n",
        "            wav = wav[: wav_len]\n",
        "        feats = frontend(wav).squeeze(0).transpose(0, 1)  # [T, F]\n",
        "        feats_all.append(feats)\n",
        "    feats_all = torch.cat(feats_all, dim=0)\n",
        "    return feats_all.mean().item(), feats_all.std().item()"
      ],
      "metadata": {
        "id": "ls4e9ERObSRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# 5) Model: Linear(40\u2192d_model) + Mamba\u00d7L + classifier\n",
        "# ---------------------------------------------------------\n",
        "class MambaKWS(nn.Module):\n",
        "    def __init__(self, num_classes: int,\n",
        "                 d_model=256, d_state=16, expand=2, n_layers=8, feature_dim=40, p_drop=0.1):\n",
        "        super().__init__()\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Linear(feature_dim, d_model),\n",
        "            nn.LayerNorm(d_model),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(p_drop)\n",
        "        )\n",
        "        self.blocks = nn.ModuleList([\n",
        "            nn.ModuleDict({\n",
        "                \"norm\": nn.LayerNorm(d_model),\n",
        "                \"mamba\": Mamba(d_model=d_model, d_state=d_state, expand=expand),\n",
        "                \"dropout\": nn.Dropout(max(0.02, 0.05 - (i * 0.005)))\n",
        "            }) for i in range(n_layers)\n",
        "        ])\n",
        "        self.pre_classifier_norm = nn.LayerNorm(d_model)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(d_model, d_model // 2),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(0.05),\n",
        "            nn.Linear(d_model // 2, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, lengths: torch.Tensor | None = None):  # x: [B, T, F]\n",
        "        x = self.proj(x)                                        # [B, T, d_model]\n",
        "        for blk in self.blocks:\n",
        "            residual = x\n",
        "            x = blk[\"norm\"](x)\n",
        "            x = blk[\"mamba\"](x)\n",
        "            x = blk[\"dropout\"](x)\n",
        "            x = residual + x\n",
        "\n",
        "        x = self.pre_classifier_norm(x)\n",
        "\n",
        "        # Mask-aware mean pooling over time (no time downsampling here)\n",
        "        if lengths is not None:\n",
        "            Tprime = x.size(1)\n",
        "            mask = (torch.arange(Tprime, device=x.device)[None, :] < lengths[:, None]).float()  # [B, T]\n",
        "            x_sum = (x * mask.unsqueeze(-1)).sum(dim=1)                                          # [B, d_model]\n",
        "            denom = mask.sum(dim=1).clamp(min=1.0).unsqueeze(-1)                                 # [B, 1]\n",
        "            pooled = x_sum / denom\n",
        "        else:\n",
        "            pooled = x.mean(dim=1)\n",
        "\n",
        "        return self.classifier(pooled)                        # [B, C]\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 6) Evaluation helpers (loss, acc, macro-F1)\n",
        "# ---------------------------------------------------------\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, device, criterion):\n",
        "    model.eval()\n",
        "    tot = correct = loss_sum = 0\n",
        "    all_pred, all_true = [], []\n",
        "    for xb, yb, lb in loader:\n",
        "        xb, yb, lb = xb.to(device), yb.to(device), lb.to(device)\n",
        "        logits = model(xb, lengths=lb)\n",
        "        loss = criterion(logits, yb)\n",
        "        loss_sum += loss.item() * xb.size(0)\n",
        "        preds = logits.argmax(1)\n",
        "        correct += (preds == yb).sum().item()\n",
        "        tot += xb.size(0)\n",
        "        all_pred.append(preds.detach().cpu())\n",
        "        all_true.append(yb.detach().cpu())\n",
        "    all_pred = torch.cat(all_pred).numpy()\n",
        "    all_true = torch.cat(all_true).numpy()\n",
        "    macro_f1 = f1_score(all_true, all_pred, average='macro')\n",
        "    return loss_sum / tot, 100 * correct / tot, macro_f1"
      ],
      "metadata": {
        "id": "9fcCqDeXbThA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# 7) Warmup + Cosine scheduler factory (per-batch)\n",
        "# ---------------------------------------------------------\n",
        "def make_warmup_cosine(total_steps: int, warmup_steps: int):\n",
        "    def lr_lambda(step):\n",
        "        if step < warmup_steps:\n",
        "            return float(step) / float(max(1, warmup_steps))\n",
        "        progress = float(step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
        "        return max(0.003, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "    return lr_lambda"
      ],
      "metadata": {
        "id": "Pl8YImMXbUkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# 8) Main training loop over the config grid + TensorBoard\n",
        "# ---------------------------------------------------------\n",
        "def run_experiment(cfg: Dict, ds_splits, global_outdir=\"checkpoints\"):\n",
        "    d_model   = cfg[\"d_model\"]\n",
        "    n_layers  = cfg[\"n_layers\"]\n",
        "    epochs    = cfg[\"epochs\"]\n",
        "    base_lr   = cfg.get(\"base_lr\", 0.001)\n",
        "    weight_decay = cfg.get(\"weight_decay\", 0.1)\n",
        "    label_smoothing = cfg.get(\"label_smoothing\", 0.1)\n",
        "    d_state   = cfg.get(\"d_state\", 16)\n",
        "    expand    = cfg.get(\"expand\", 2)\n",
        "\n",
        "    # Unpack datasets/loaders prepared outside\n",
        "    train_dl, train_eval_dl, val_dl, n_classes = ds_splits\n",
        "\n",
        "    # Model / optim / sched\n",
        "    model = MambaKWS(n_classes, d_model=d_model, d_state=d_state, expand=expand, n_layers=n_layers).to(device)\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=base_lr, weight_decay=weight_decay, betas=(0.9, 0.999))\n",
        "\n",
        "    steps_per_epoch = len(train_dl)\n",
        "    total_steps   = steps_per_epoch * epochs\n",
        "    warmup_steps  = int(0.12 * total_steps)  # 12% warmup\n",
        "    sched = torch.optim.lr_scheduler.LambdaLR(opt, make_warmup_cosine(total_steps, warmup_steps))\n",
        "\n",
        "    # TensorBoard writer\n",
        "    run_name = f\"d{d_model}_L{n_layers}\"\n",
        "    writer = SummaryWriter(log_dir=f\"runs/mamba_kws/{run_name}\")\n",
        "    writer.add_text(\"hparams\", json.dumps(cfg, indent=2))\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
        "    best_val_acc, best_path = 0.0, Path(f\"{global_outdir}/{run_name}_best.pt\")\n",
        "    best_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    global_step = 0\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        running_loss = correct = total = 0.0\n",
        "        pbar = tqdm(train_dl, desc=f\"[{run_name}] Epoch {epoch:02d}\")\n",
        "\n",
        "        for xb, yb, lb in pbar:\n",
        "            xb = xb.to(device, non_blocking=True)\n",
        "            yb = yb.to(device, non_blocking=True)\n",
        "            lb = lb.to(device, non_blocking=True)\n",
        "\n",
        "            with torch.amp.autocast(device_type=device.type,\n",
        "                                    dtype=torch.bfloat16 if (use_amp and torch.cuda.is_bf16_supported()) else torch.float16,\n",
        "                                    enabled=use_amp):\n",
        "                if torch.isnan(xb).any():\n",
        "                    xb = torch.nan_to_num(xb, nan=0.0)\n",
        "                logits = model(xb, lengths=lb)\n",
        "                loss = criterion(logits, yb)\n",
        "\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(opt)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
        "            scaler.step(opt)\n",
        "            scaler.update()\n",
        "            sched.step()\n",
        "            global_step += 1\n",
        "\n",
        "            with torch.no_grad():\n",
        "                pred = logits.argmax(1)\n",
        "                correct += (pred == yb).sum().item()\n",
        "                total += yb.size(0)\n",
        "                running_loss += loss.item() * yb.size(0)\n",
        "\n",
        "            pbar.set_postfix(train_loss=f\"{running_loss/max(1,total):.3f}\",\n",
        "                             train_acc=f\"{100*correct/max(1,total):.1f}%\",\n",
        "                             lr=f\"{opt.param_groups[0]['lr']:.2e}\")\n",
        "\n",
        "        # --- Epoch end: log train metrics on NO-AUG train split, and val ---\n",
        "        tr_loss, tr_acc, tr_f1 = evaluate(model, train_eval_dl, device, criterion)\n",
        "        val_loss, val_acc, val_f1 = evaluate(model, val_dl, device, criterion)\n",
        "\n",
        "        writer.add_scalar(\"train/loss\", tr_loss, epoch)\n",
        "        writer.add_scalar(\"train/acc\",  tr_acc,  epoch)\n",
        "        writer.add_scalar(\"train/macro_f1\", tr_f1, epoch)\n",
        "        writer.add_scalar(\"val/loss\",   val_loss, epoch)\n",
        "        writer.add_scalar(\"val/acc\",    val_acc,  epoch)\n",
        "        writer.add_scalar(\"val/macro_f1\", val_f1, epoch)\n",
        "        writer.add_scalar(\"lr\", opt.param_groups[0]['lr'], epoch)\n",
        "\n",
        "        print(f\"[{run_name}] Epoch {epoch:02d} \u2014 \"\n",
        "              f\"Train {tr_acc:.2f}% (loss {tr_loss:.3f}, F1 {tr_f1:.4f}) | \"\n",
        "              f\"Val {val_acc:.2f}% (loss {val_loss:.3f}, F1 {val_f1:.4f})\")\n",
        "\n",
        "        # Save best-by-val-acc\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), best_path)\n",
        "            print(f\"[{run_name}] ** Saved new BEST ** (val_acc={best_val_acc:.2f}%) \u2192 {best_path}\")\n",
        "\n",
        "    # Save last\n",
        "    last_path = Path(f\"{global_outdir}/{run_name}_last.pt\")\n",
        "    torch.save(model.state_dict(), last_path)\n",
        "    writer.add_text(\"checkpoints\", f\"best={str(best_path)} | last={str(last_path)}\")\n",
        "    writer.close()\n",
        "\n",
        "    return {\"run\": run_name, \"best_val_acc\": best_val_acc,\n",
        "            \"best_ckpt\": str(best_path), \"last_ckpt\": str(last_path)}"
      ],
      "metadata": {
        "id": "4AKB7EtibViJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# 9) Data prep (MFCC - Masks only on train)\n",
        "# ---------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Load HF dataset\n",
        "    ds = load_dataset(\"google/speech_commands\", \"v0.02\")\n",
        "\n",
        "    n_classes = len(ds[\"train\"].features[\"label\"].names)\n",
        "    sr = 16_000\n",
        "\n",
        "    # Front-ends\n",
        "    frontend_stats = WaveToSpec(feature_type=\"mfcc\", n_mfcc=40, n_mels=128,\n",
        "                                apply_mask=False)\n",
        "    frontend_train = WaveToSpec(feature_type=\"mfcc\", n_mfcc=40, n_mels=128,\n",
        "                                apply_mask=True, freq_mask_param=4, time_mask_param=15)\n",
        "    frontend_eval  = WaveToSpec(feature_type=\"mfcc\", n_mfcc=40, n_mels=128,\n",
        "                                apply_mask=False)\n",
        "\n",
        "    # Waveform augmentations (train only)\n",
        "    aug = Augment(shift_ms=100, noise=(0., 0.01), stretch=(0.95, 1.05))\n",
        "\n",
        "    # Dataset-level normalization stats (computed on train, no aug)\n",
        "    print(\"Computing dataset stats (MFCC, no masks)...\")\n",
        "    train_mean, train_std = compute_dataset_stats(ds[\"train\"], frontend_stats)\n",
        "    print(f\"Stats \u2014 mean={train_mean:.4f}, std={train_std:.4f}\")\n",
        "\n",
        "    # Datasets\n",
        "    train_ds       = SpeechCommands(ds[\"train\"], aug,  frontend_train, mean=train_mean, std=train_std)\n",
        "    train_eval_ds  = SpeechCommands(ds[\"train\"], None, frontend_eval,  mean=train_mean, std=train_std)  # no aug\n",
        "    val_ds         = SpeechCommands(ds[\"validation\"], None, frontend_eval, mean=train_mean, std=train_std)\n",
        "\n",
        "    # Loaders\n",
        "    dl_kwargs = dict(batch_size=128, num_workers=2, pin_memory=True,\n",
        "                     persistent_workers=True, collate_fn=collate_fn)\n",
        "    train_dl      = DataLoader(train_ds, shuffle=True,  **dl_kwargs)\n",
        "    train_eval_dl = DataLoader(train_eval_ds, shuffle=False, **dl_kwargs)\n",
        "    val_dl        = DataLoader(val_ds, shuffle=False, **dl_kwargs)\n",
        "\n",
        "    ds_splits = (train_dl, train_eval_dl, val_dl, n_classes)\n",
        "\n",
        "    # -----------------------------------------------------\n",
        "    # Grid: check configurations\n",
        "    # -----------------------------------------------------\n",
        "    outdir = \"checkpoints\"\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "\n",
        "    configs = []\n",
        "    for d_model in [128]:\n",
        "        for n_layers in [10]:\n",
        "            configs.append({\n",
        "                \"d_model\": d_model,\n",
        "                \"n_layers\": n_layers,\n",
        "                \"epochs\": 100,\n",
        "                \"base_lr\": 0.001,\n",
        "                \"weight_decay\": 0.1,\n",
        "                \"label_smoothing\": 0.1,\n",
        "                \"d_state\": 16,\n",
        "                \"expand\": 2\n",
        "            })\n",
        "\n",
        "    results = []\n",
        "    for cfg in configs:\n",
        "        set_seed(42)  # keep runs comparable\n",
        "        res = run_experiment(cfg, ds_splits, global_outdir=outdir)\n",
        "        results.append(res)\n",
        "\n",
        "    print(\"\\n=== Summary ===\")\n",
        "    for r in results:\n",
        "        print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6e2055c280b14d199a27380b4deb2f3f",
            "37ce0a7c0a8747f6a14164e595554e7f",
            "589a0aedc2a144129b12332d932f896a",
            "5a1dba5781604ec7b33aa3549e9a1c2f",
            "041560e5e16d4c9e90c825172804b481",
            "a27bfcfe6fe743a49f6d0069324a0f55",
            "21e5bc1bcd504c6db3c974151e370b1f",
            "982e52f302044d72beda226fb90e7458",
            "36b01e1e7fee4e398ca5ff5496edd0e4",
            "31847c9ab52241d79a0ccd409be2e9a0",
            "089f817bba664dd3946cc7cf9557f126",
            "11f0b3be75364b45a7175ed0e2d68e41",
            "941da01c0acb40bebb158ef8f30c8775",
            "e626eb78b2234711bfadeb24d2cf8f16",
            "195f767fe67240a5bc13d860edf3c26d",
            "5df0ff2ecc4c4928bc1f3e68e3a1f49e",
            "d8cbb60ba7b14a1cb0276e5d429c3d95",
            "0c87184e0a794ab68a3133180ac42f49",
            "f422324e482a4cff81334a3853dd6220",
            "628bccb1991349fea85a47442f86abe6",
            "d5b579653caa48bf9cf2775eac9acb76",
            "bee2227ff74d4b5abf7c47c71a6e4962",
            "5dd972ac68c04896b4f02a4fe7e18506",
            "d82592d778304eb084296b3430dbc0c9",
            "577992b17d064657ac04ab83ae9237b3",
            "22c139624d434df2b988b295c24bae5c",
            "15c46df9c8c6475cbe26e31bb47126bc",
            "163e5e2084904ad0b7c4b03685073e51",
            "8f6be12743044eba995d3822743ced4a",
            "6fb9cbe06f89412a97393040d3430525",
            "0cb8c7fda02f4127b54e5d55c2bf8f61",
            "c2a1f93f6b374c5c9c1407998cc493d1",
            "db575f7768c4478fa785b6e4a09f85b8",
            "1fe365781dfc480fb1dccac14540271d",
            "6d01c4b9d2cf4e719e8d09677a08dd70",
            "2b62338c449c420f941fc8d8787f54de",
            "50581f2976164ed29a05e7a5914649ac",
            "960e836b30c845a0aacc580f7ec2dd77",
            "c2bad01b020f44c7aca73eac6fe24421",
            "4bc5db61fc9c4f16ab46799ad3b3098d",
            "90992beae54444b38757b07feca5fcec",
            "f08e445173b7423383c4b90429e3c7d9",
            "13608554837440f18c70805f127d1134",
            "ed8768aa43df438399876efb04ed716e",
            "82b0d19dda964d9b960465307951250e",
            "c004bce88dd14ee682e97a38369ea46d",
            "82848e61e15c491c99d566e8af74defc",
            "450aa15b85eb499e998f4194e726ddc7",
            "f8f393c8f57c49488a71647dc120e96f",
            "9c53041a4cde463287176229aa1c0cbd",
            "19d46c89cfea4379881d8b7f78a27958",
            "f2e79f2103e84006806e8275fb836c4d",
            "fbef2829142242e38b8290effa79e7d4",
            "b6ad83198c6a42b282ae981f34bad8a5",
            "021076ef22cc41a0a51d5c1029040676",
            "2768397720fb47bab7e7ece0e0924795",
            "a81c391355e74cdeaa928c72c3c6fa5f",
            "68a464106133443889362f0259b70d04",
            "d2261feee1cb4f80be141ce369bffbcc",
            "7705b35ebad949c1b0693941ddd75700",
            "7af256921d2d447a88420011de522ed3",
            "37fbc0243c914b69a19e45fdd3652477",
            "25c30a049a9d4fadba5dc94a55128b35",
            "ae4df94368654a4989d9299dec8a8b62",
            "46a90c2f88e4414cabe5cd08951612bb",
            "f49d1ef42aa144fabd603b74d3d98b28",
            "c4a14a7f7cc648d0a4582466eb261577",
            "796c4ff2ff0241318f825faeaa76609a",
            "a6e240547f324204a596dd5ad6d703a2",
            "46404f9094e442219ae63b0a197beacd",
            "f28804effe9042d18ec0f3e7dde01aa8",
            "1d33eeb9c1dc4fc4bbe26fdc9f7196f5",
            "21c5350f99724792a6f2766a3e6a724e",
            "ab731e913d0849919941b27285abe25a",
            "2a627a43edec4e8795cc632346628f0d",
            "4f00a4ccc1444745811f2eafe918bde7",
            "cf9382b1be0c4897be803ca2bc0e9ed0",
            "7606364fb0384ea090a5a25e4c9d271b",
            "74330536709945d19eb163425f568dd0",
            "3948388fcf2340b8b71722541a99500a",
            "98db6e55e2c14624b071e2c040f9d7f6",
            "790593d694164825a34026ca5e2a6465",
            "33682e56628448618bf89a53a661c3df",
            "4142121949ee4102b06b02e2014b6bab",
            "b023b7b3cf9748219924a729d973f4e1",
            "b8513834329346099bee715ec223cbd8",
            "67215846c28b4b1cbd670d9a60a8963e",
            "5fc31fa739b5488485f6eaabf3c821c7",
            "d68448834be640d69712a19c385f979d",
            "4f62283df90149b8b52f14dccd9cdc59",
            "19837bc75cd24944b59bf1b414952db8",
            "1afb4d58f1164f1292786c156ea644d9",
            "231cb02b96a04ac3a05825742100bb55",
            "cfa0f1cfb3bf48b0a0d470a1686137fd",
            "5af5f1923ae6452393b88c3f390cfef8",
            "3b7856f911f744e4a2415668cd28df7f",
            "b5674df157a14533bffed33868b00061",
            "484da71e6703423db91f9b886c94834e",
            "339dc66fd57647aa923492e7ac284c82",
            "e2726a01db194fef896157c247fccced",
            "ab65b6fbda02424a95de3ace12961381",
            "9cd26ff739624501b943e5de23b597d2",
            "da85b205ee1049a2811a6149a7e43163",
            "81a9491193a84fda8e723ba577452ec9",
            "3413b55fa3e34b2baa40edb02e51614b",
            "c99e9d4878f447b9bba964970a3a5778",
            "62bc24e8b91d4d6c916b167eb06f628c",
            "5ac4fcaf807743d28d1ac2ee447ef442",
            "10b28ca6817d4b5fa7e97bae24fe4bdf",
            "71826a4bb0564a98b5a033e3d0a1c6eb",
            "6a0c0db3ae0e436e919e1e10ad18e53e",
            "d8fc10f573bb4c0397530114e3ac4e36",
            "6fbbdbf2e4514ad5919a2d6cba5441fb",
            "9dca5bb7416d4fefafa1a1c81c2d33a8",
            "c5b0ac47e2e44d3298308275ec58b034",
            "cb3a1cf5a2a74b18a1ea59882c3df9d7",
            "f5fe918fdfdd4e998e290d282d48bea7",
            "15b2c49be5ab44e69dd6a253dfdaba07",
            "417c01e66ebd4bde8a6840e2493a516c",
            "fd82e6a7b41d4fc09f09077af70f72bc",
            "6928d46c8d7e4ec882e2bc1a12e020ff",
            "82ef2f86d51447a1a2f0ca6419704705",
            "03afe07c0a9943c280a95e5fec6d8b37",
            "00ad5213cec341da8939e14e6f5c2070",
            "5666f1e778ef47d0b2c553d967a4d1a5",
            "4209dfbd289444ac93ffcf90f14ce607",
            "da08f31846ad47d883a17da8da0be708",
            "b3650235ca964ee78aded9c10651d675",
            "af35ab028e2e4235a0d5cb95dab32649",
            "e3365c9a6c8b4b7a97f354d3810fc111",
            "0229e884204b4455835bf37030ec4e70",
            "dfee08e352794056a6b85303531f806f",
            "f1cf9a7805b841388297b88b44b5f0f9",
            "48155fbae84e4e83b99f56d9ca9f105b",
            "f9a35d2db17a4c9f9b8777e7d16aa6bc",
            "b374e786b42f49c39fb3bed194d94589",
            "ec6c48f0fc554742b0e8f5aca9208310",
            "e169a9bb54944230b610e9dc2148bf9a",
            "3f50f622fbf541b8a2b8c3945475eec9",
            "5505144a08f544e18c5fd27853963959",
            "f5c9b3df1a1840f4ba4a4128994d88c6",
            "31fd945eb7604156be7a4f3916a24b2a",
            "031162f4457747d690bf96aada95bc9d",
            "50d449ba19694d0f8d2cc6e66703829b",
            "cb566cb872f2448c83eeaa033ca42c3c",
            "fcd9a1ece9ca4684b32eeda567f80d78",
            "c685452fe8b8437b94179cfc26a99b8b",
            "5f738f158a4540e8ac02682c374f59c1",
            "08cfb2b62db6416eb045440d03828a41",
            "21d147e57f7f4529805c6ae1161aea7f",
            "4a4a9bdc6b34422ea7b638b3f87b40b9",
            "dd842c3007eb4b7996e4e18dc9c81aed",
            "1904cf75f2754a5d9b6ef25597090f4a",
            "6766c647121e4efc9372d80565ff2324",
            "4295a918d4564c028e876208d7cb86d9",
            "5e00cf349f864d43bbe30835c3a66438",
            "46ad4922d2394aafb1d38d9271618157",
            "cd291cd158264e45bd525ded30bb05c9",
            "d31734b662b048c7b33b21caa16b4185",
            "69e2f8ab16bf435ca2f2de9ecb23212b",
            "6c7ef5bcc8e34858b72ec7ed23bc6c2d",
            "d188bd63a02848de9f36a9e21ccae0da",
            "f63c8116bdce44fbabe41f657440de1d",
            "72ed735051fd489a9dac38772897c44b",
            "487f2a261cf24414af9d269a2876a2a1",
            "d0d9299c27dd4d218cd0cc209b55ed0b",
            "4f16390c847d453da294b2ee1b4837cd",
            "7d3588d9b9644760aa3d8078b101bb78",
            "b11cca553f3a45f6892fc0f0b8227de0",
            "38cc792f6acb40e6aa708092b6a27794",
            "a8cb6f8389044067ba8982c200548dbe",
            "0fa9e7ea849c4b99817fdaeb999c9679",
            "9fd714ff11ad455f9a9c561f3291cf50",
            "f63bab0730ac4849a8b516bfebe73b05",
            "990e50375ad346aa9d4bbd1ee88e4b98",
            "f85ef5c5e8a94975b4e1722e61d3c93e",
            "65b96f249f384ce780814eed19a78507",
            "5580bba3df62404a9db2a43acd720da5",
            "fcacbd6537f8449987ba403feb9cc403",
            "d4c1ffccca7e41b18181d0e60c7eeacb",
            "ec1797631f014838a4e68854a184195e",
            "b839a00095dc47c7af77b2edc696f1e1",
            "51a3e360765e421987520de0173aebc6",
            "01fb4c5cd1944fd7b19cf0f555697ed8",
            "86bfdc0615464ad9b20a3ae4738d631c",
            "1d22710f810b4181b35efce35aca3649",
            "d0d945241443467a9092092158f43e47",
            "f394b4da4ce343dab059bc7efb5f2c0f",
            "d51d3a6e815540d38e137181f446def5",
            "399d2417011942679f03df39664605a3",
            "3b4162893625402dacc2f1c183263868",
            "7b8d6fda53bd4e718a62955eb6228032",
            "15ed40d22bcf4865934677d7123f45a1",
            "6ee2085297ac4707a74db36b836041bb",
            "0dbe7de8b7084737971bb9c281284e11",
            "4f7e177eec094bbcac4f7900c50ddcbb",
            "049888273e28453aaac03560513a567d",
            "4b23fe5209f74f02bc2f78ca3c4612a4",
            "5a47bbad07364ca596258083c3d147ec",
            "f5207eeda9604c1c870acd5aa768bb9f",
            "2fb1ec310ba347e993a6be0066f1f012",
            "f065063f59c445aa8975e2792efdb2d4",
            "48d6ed2895d44b5c855d73abb100bd60",
            "17bab06470834125b0956241dc93ec33",
            "befb473359f441f7a0fbbf236e6f604a",
            "34d0117a5a434606bc3fac65376a8e4b",
            "8dc59e1323f54df8a62913fd7029026d",
            "5b2da433bc98436ca20dc6b6753f88b1",
            "2c37d6343cba490e84ef4d46081318f2",
            "7ed2574f6982449786781f897deda681",
            "a398647e642544af984f8c6f5c968234",
            "fccff54db09b4d41b789b83a5f4e8578",
            "d4287756e1814197826c135e67101f09",
            "54fa7627408c47d0a7fe67476a4e0418",
            "eef5000c8a5a4949804ad40997508445",
            "9dae2e4146a6434f940ce324e835be9d",
            "fbf597c7bd54440c9f987aecc24c4556",
            "614add6f4aab431f8dfb99514092b02c",
            "214b6018eab5494a9cf379b1618d6ea5",
            "84d0a94c1c6c423ea9a0c4b3711d07c9",
            "fafb8f15851348759dfc7a5be5ff9bb8",
            "93d1e2ace14e4162940e055fdf88c097",
            "992535b5ff26472d9f514d31d789d52c",
            "577cb029a01c4dfdb8f22475e2ed51d2",
            "bb287af764fe4c60ab5806abfe0b914c",
            "74190d95612a4f48b6e5d30336dc0387",
            "a3c239e2fc384156b3d47570c0b2dfc1",
            "ec695fe2542a4bec8e7090feab8bfe59",
            "ddb223d3bbcc4e10879a111e9cce3328",
            "662527650e02421ebd57764c71b9cb97",
            "dc088e42c93c457c86fa0416418a891d",
            "18312bf0dca7435c82d3befb94855e25",
            "3ee6d190768446f184d05a13309375f7",
            "f3954151e24f49a993441cac59359008",
            "d338031f1a594db0b5d3379e76cb4984",
            "c41a4a429e814a2eb875d849f1987ea1",
            "cfae0ea5c4894fa4a62b23e23ad13cd6",
            "80a33758336d49448ba7b4e019cc13f8",
            "f9905900e7e442e7a2e11084505785c4",
            "ee8467fb818342e88a313c02a853a685",
            "19cd062222354c31a038035f37796797",
            "f12752a238a94814a664ec8ad5d00b23",
            "045a6215132a4fe2849cfd7c0c0e7780",
            "2ca41817b4ca4da1ab3bdb6affb84828",
            "ca250c06bd7b4ee4bf39d51da0118b96",
            "3661a42266a0473a8dc7fbd8e6b5fc59",
            "930ef99114474a26af076328583814f3",
            "2320f3db50ea4448ace1d01644f8daec",
            "83d48ac88d5e48e1af35b7fd9ff9fd9a",
            "aa40f9c6a8e8411ea06d95e50aad6f5b",
            "9094d85582cd4b9c8060bd63c26a6dbe",
            "c7fb09a0b3774f1d96868fb254d0069e",
            "3a1d36e2381a4e5dbb124be7ea5f8cba",
            "2bd004e02c844f3aa6bc1ee2a17d0c09",
            "c95ccb16b55c4e178a80b6503bc6e701",
            "b1319ac64faa48b2a4060acd89c27b6e",
            "2c5b8e0060644a64b610a168a7d12971",
            "665066c2a17f4a6dabca9fb62266de08",
            "e6cb4aa7822b4837a40d42623b1141ff",
            "f03a6625e7544a18a404f3d351057928",
            "f67631f7349d4cab89f0026048f755e9",
            "c05c226bebe84bf4b7e555f0e7b82e24",
            "9923460f088d44fc90a4ad60fa6f9098",
            "f42ed93130b3479bb47735be5d191eee",
            "f288df3413b14e9b8702ddbec5a6a6e6",
            "9091296a88b04f458f99ceab71721523",
            "da9b974b6df0488b925e86ed1021bdc1",
            "9f21e122233346c09d8ac40d0269659d",
            "b7247def9dcd45a98b265a4e58cb081a",
            "018db35c617c4062b27a2741a9445011",
            "50587a2555874468ab5d96fe555a27b3",
            "93d678864efd49448f55ae4d07117753",
            "4557aca91f7941fcbce363eb8882da2a",
            "8e110742bcee4daa9f3ede4427008499",
            "d799300be21f47df98e319d0b31effa3",
            "cd6261a60c8f4a95b15e5325e59b984e",
            "f9a2c6d3d4e34a799d81b25e2300ed49",
            "48d1122649cd41eb955cf3bca62c73b6",
            "8d85dbfc35824eb3928129cf411e782e",
            "42ba8e2100c0422ebdf547eeb59b0ca6",
            "1a4e847270054d1892708127b505e8d7",
            "20550ce44fc44a9787d565f2bad3227e",
            "58f9c15b6d1c43d5ba4973f6d8a7ce2c",
            "cae8c3078b564ea7a5e5ed3c8fa17ece",
            "560a08dc24d944ce8ec75204fb991f03",
            "0047c5452a1d461d86b2f8388ba7fff6",
            "1f5d49b3a2b240c0b36a627bc3c81306",
            "1111430e5eb445948b7aef8e2314d5bb",
            "59633669aa27489b8905b12ce299d504",
            "517dae5f18034fba8d37959519840f0e",
            "ab0d37eefe7a4b05b6771ab53ab1ec5b",
            "82897a75b37b4cb88ede036b9f086854",
            "c194f203cdaa4070a62c8f1eddec8b6c",
            "4f83ea0fbc1e44a083e5f420563dcf2b",
            "8b59e5f0f7ac42aea685d184cc42949f",
            "9c136a7feca64b0b8fb42334bd2ff10a",
            "356eb049346f4c49bcad964df4df84fe",
            "4ab28739a2ea498ab5b9ed63a7d3fc87",
            "29db53344fce4a6682ab199deb7b0565",
            "3b05c89c7a3141a29c931ad24f447d57",
            "03ff28aa91474eed81ff8296f4e261f0",
            "28e0d6dfa896405f85dbcc36cfeb736b",
            "526affec4b9c4b32912a192c22d9824e",
            "4b9e2b9aad494ec2a8470e50de1f1174",
            "4850e34b8cb747a7aae95a06054f6baa",
            "fc066fc18c1547df9cc46163d718dfc9",
            "13bceed132d34f59a74a3eee984508eb",
            "2e3bc295d774469c96653400b68e2106",
            "238b1cc16de146b3aecccdfe8edf3168",
            "0ba26d478bbc4437af72a8ba1ba98ef2",
            "f2966fd623644a69bf3c40cee3489261",
            "769b578aca414f99aedba148c40350d7",
            "77c352cab65541fb9183ca9118b48464",
            "75b02baadaf24b0bbba6e69a184c256e",
            "4a0eb6dfbd8d41dd9c306a49a994aeaa",
            "1af47838c7f54a7ea5a5b83269365f41",
            "d189b6d8dde34c4ea89f881a4aa1769f",
            "b5dbdaf830144acea7193d850bb14e67",
            "6a9c52fea2ca43c89db22fc2d30ac4e4",
            "1b11939c9767448cbb3f2a0212c13f97",
            "4409b13643e0481e9c5011643f954fb4",
            "afbb80e261bc4149b17e717b6fc3afc3",
            "26761bdd2d0f4607836bb8f2315a404f",
            "e721a47b116c4a0bbcd10d44a96729a6",
            "5d43b797e5c141c0bc007d8cc98d63b0",
            "48b16a425ba34c05bf16de830d8f6427",
            "154ea66f020e48639000f52362f2ed31",
            "28b125703fbf4edcacde6d3867278ec5",
            "14232500abc24a759fb6eed8d3bcb12d",
            "f13738ccf1c44a3d89c4b1816fb8fd5d",
            "abfba0b3ece443d39e5ff80047b3533d",
            "3577e8f4bba84189b17fc31597abfdbc",
            "1df5c666cdfd4f49a16486a455fe065c",
            "36a60e6b06234ce39f1c3823eb048c1a",
            "225466d501714133b54ae4b4dd1b2f55",
            "4db59490fcdc458cb0caf4b0866ed6f8",
            "326b3d3e9126404a85ac4764e6e39c34",
            "2eaff95f89e649e5a22840f5cd75eb59",
            "89513271abf649dbb4a82df58c3b5c66",
            "614b708ec199455f8abab0ed1224b58d",
            "3013682e625a46ee81e4495e8ac9d52b",
            "fdc95ec7deee4e948305136d3036f12c",
            "9d63546942cc48faa88d9e56386d820d",
            "e60a17cfd03c4186bb2da39e61cc050d",
            "14bf266711f04a1f90a8432fa21006cd",
            "59f8807192f3476eb60a32eb9d1c7765",
            "9db62a24dbc94e4d9370fb6a5087b111",
            "076cf2640ad1486289fcce3527596042",
            "0bd45e9216b94709b8a0da56af1efd47",
            "48fd897a32ed422590067aefc68ed645",
            "e7c7813d82f14257817b58da7e30541f",
            "e99b9046f1d146408dd9e68f673591be",
            "47a6fde173fc4e96925301aa19299c31",
            "d08c09ceb59345eaa3155c730a1b8a70",
            "1590ba0fc5a6416fb49b234781e340b9",
            "2d4e3318d2404d349601d7ccedd6160c",
            "ce74125d91f445868e3cae9a6856124d",
            "6e7c3844bbe144c9bcb1f3a0c5bcc61c",
            "069369369145485d8282a49a4e59a7d8",
            "f74021beaf98478fbffb5dfe0245bddf",
            "3a9f9b36047541afa4df8e022f078c85",
            "413253fb184c4cf3b1e17351dbc1aa8e",
            "6d82dd588de64e7dae41028c37bf0db8",
            "1aecaf77f10b4dd3aff67dcb2a186217",
            "aadedf7c45dd4f3aacdc9cf0d07677c6",
            "ff1a07ce791743dfb82676a766f310d2",
            "575b416f6b084056a86b28d8cd69d49d",
            "e283fe06ed4f44e4b86b6d6b4f649d01",
            "4d22a15cb54c40e3a172b5abed6f53ef",
            "7516639b88b94e2d88761fc877b2f27b",
            "e0ba35610df1443f83d20820429d7d06",
            "1c1c1e94889f41c2be5c764fa2d12582",
            "806471e882db4d9093e4fd6c077b7257",
            "c43000f5618f43879298ad8a7650b256",
            "67c3e74a9e404e33bc912c963703bc07",
            "34ca442326ee4d3f9dee68196058e1f9",
            "6d55bbdf34264d5c8344b9bb68f426d0",
            "db67afa788f8480f97346d0b21e8a2e6",
            "b244d6bae7b44ea8973b94da72a8895e",
            "3794c8a4bd6442e8a78ea63275bef034",
            "88f1027ff9834613982b2653599ef8ee",
            "e9d518b1ce744289bd444129fbba1b05",
            "004f734c368a42f0a60a584a5c131621",
            "14568246d2ff466ab8bd74aa8f64f50d",
            "8986522df27b4d0493f6ff052505b6e7",
            "89edba936792425498b2122dd5833015",
            "75f0444e86a4447c892273d755163c3d",
            "f0fe6d2e426847869e4d70af6932967f",
            "460fb97838d74bc6b5d85e2b46471c49",
            "0283eea0a15744319538a7c6cded3de3",
            "ec6718a454b14448a073ae4527274d49",
            "30f118c5482e499d8d5d0d79478ffb4e",
            "12a74b14bcf24e3a852c597c641f65f0",
            "e771a299fcad410ca5c4ced3c6926168",
            "a245aefb40304fb29989195fef7e7fc3",
            "f025bb1aca9a4edf8307342a95edf46c",
            "7b8c2cdae1de4c67899a42c1efd5d78a",
            "d2c6a5a629b14e4ba0451e50389e91fb",
            "46ddd83d3d944138b4d323312f2bcdd3",
            "7a512888fb164a08a49e5d762d2c09fd",
            "48d39a3a06b44529a0f289cdee790f5d",
            "d85691e5aa69476d9e55f477c75a4e47",
            "e9726d4caca640379f98279d0514bbd0",
            "3a5d6e3a8abd4951960c3984ca5f873f",
            "12db2026722a4130946be71705cf253f",
            "99c594f446074d35939c22df0b4e2d81",
            "0558f81f2e214e11a66f9e3842b30e76",
            "82008ff5fcd8499f8c2103a181092ffd",
            "aee0d03c54874c30b47cfa34e3349173",
            "fd8a4eae9db84eb499d1e9ba4f7b0abe",
            "19824ac02c32489395b1ee9e88564416",
            "376bd75ea0b846a2a934a9d6774030a3",
            "a2686c3dd7db45128dc8f1e9b787cd54",
            "2a5e0f88b0f74b649a7c0bc07bb1f3ba",
            "9403a6d49fea45048230fa9291fa47bb",
            "2b706dd073044972935c0d32497af2ed",
            "16e267c1f4d14f269be171ca7023b730",
            "978f1711fb86410692d0e8b77757d42f",
            "94212f116a1245eeb85a4bf49bf09f3f",
            "751bab43063d4a62a551eb9f92e875c0",
            "b21052af3f82458e82beff61e9d3a9b0",
            "965dc076dde44897b080c3e1056e78e7",
            "3226ed89fab54fd690e3ebe094155bff",
            "402db3639b3d437298cc3ba4e98c20a6",
            "ae6081c49ee346bbbecc826b48d96cd7",
            "6169f5d82e05412ca8a150442afefdb3",
            "be657804c17d4f27b13dc1a8427debff",
            "cdb6075a34c340dfb4b479cc06e03ab3",
            "0e19af35162c41b0b5dd448a7b6289a3",
            "29ca4480f29e4c4dae39b826322a8e51",
            "7235add91ab64307bfac76f579ab81ab",
            "50378ee8c23047e1adbb102b437854f0",
            "a9590ab335464f09ac5a4040d5483ae5",
            "77a920e8958b4e5ea1ba5d33bb7ae8ad",
            "98d84a0009f94ae0bac8090ccd4dad09",
            "16348c82db6e481ab7cff2c35eca817b",
            "4a0a5cb47cef4a6bb55977f10c6d88e0",
            "fba21d2964c942a0b34fa87242cacd05",
            "778fda43d0184810b0ac4fdc82740157",
            "6ccabead475d4ff3ab8050e2b7d96261",
            "dc12255a021b47bb9727d573e25e0ee6",
            "44e5356d9d23443bb4d4f63538b29499",
            "093b20fa8fc14acda5d223830f06034a",
            "45f2bd37d57c46a0a311ebc989c7d0a0",
            "58dfb53f103d4786b22a8e8450a23639",
            "e041935a586046dab68a54e65be27cab",
            "8afdc1371b6e4a7494425223350ddce5",
            "0a0800184b2946a6920c05e8f6e67048",
            "d5409aecb49949d38efa3c2529dfe8ea",
            "0973a5102b574c5c999228e8814fac7a",
            "98151c5449944cf4bed99bd99bb28348",
            "1b0b4851ce4046548426a4b0691ff503",
            "7c96b79430664557a48f1aad0074a0a5",
            "3e12bd3eddd34b9aad12810c062cd142",
            "eb79f382f52a48959c76ed4637bdef0e",
            "1de85d41108246c193a7f31104861428",
            "f3aa81b6d0f44c188b40f5b95c973cce",
            "563c57b4e4954099a92ed7f30c1862f0",
            "c8f21391f9ff4a2c8f07ca545b06626e",
            "443499123be64286a1e7c25bb6cb6a47",
            "84b6e33df65d4222b0d7fcaad0adb442",
            "74917d24652b4d5fbbbb5273df50990d",
            "8b2cbd6a91664698aebc25cb49a44a21",
            "87ca7b3d40f24c2a86e4108dcb317b62",
            "bc43659e462546908850d60d331a9886",
            "582f618a5a044acb8d074c6fb7b0b940",
            "e6dba94a72584fd9a538b56a604d301a",
            "8aa079eca8f64f8dae279caa9935a207",
            "98889dd748b846c0a4488e84dcff57a9",
            "019c7c187bb0474c80e2a22eef2d215a",
            "7bae625c618f42e98135992f2db6b6e9",
            "2beb28c2b77349838b900d5779cd3940",
            "655fc8e6ca6544ebbbcb531cd1fe6cf9",
            "b6fac97e5add46678affa9763c613394",
            "285c33be8bf84948a5647486f4f162d3",
            "465d29b41257482c93e9be3be570b647",
            "33274fb4586646a0892ebd19ea482545",
            "55ce23c2431a4410b9eaaf473283fab1",
            "3dcf125bc2894911badfbe0dd26589e2",
            "499e9826b3de4e4e98bbf3705c7297f7",
            "e007654b2ee646c3808cfeb558b2b0fb",
            "7c1782d3c29543c2b1f5ca62e0e41b57",
            "05b76ab30e6d42479c1088501fbb2e8a",
            "bb83f7c6554b4bd79609457a11936c92",
            "2b5c5bd244da4ce9af8afe9fd2fce2c0",
            "3020501737e547c0a6d02c9fc93a7acb",
            "6856f2c3abcf4e3ea9a7612c4ecc579e",
            "ca3df216fa8e43128665d6e246ed0151",
            "1db3d0b2e4dc4bfca647b226531bc79c",
            "c99fe5baadb24922b5a59dbda087d106",
            "c15c4959c8934b64929435bde56ffc93",
            "4690f34540374b47a3660a6a1c58c384",
            "cf1c8937e5ba4149998c4dae907ba477",
            "1cb1b6b87db34bf98d6fcd9f7adb5226",
            "ce5924c066e54c388ba4aa598567c325",
            "2bb72ce1a6374651872a1bfb093ee99e",
            "864632f937334885b6eece32e798fda0",
            "4f2e729301bc433799713fd283333daa",
            "17c0baca64054aedb3839ed09d34d204",
            "21e4b7ebdd0945f69bd13e31a29d218d",
            "05b78e12375e45d6a6aa499caa7c6860",
            "4141b9ffe1314703bb63650931497a02",
            "ad5023aeac8d4bf893087c8758474ac2",
            "9515e41d3b5d42cdb6e202d0f0617023",
            "48a2f5bec2bf4edeb8af508293cbc8a2",
            "8a7a6fe592384e9f8d9d71cc4dc807ff",
            "c69cdb17afe34efc9c689f361265c1d1",
            "de2794a473fd4066a8d55371abd0f50e",
            "ab6a5ecc543e41798f0a6ca4530ee51d",
            "6058ffd8b78f4a349ff4bbbd43c25d88",
            "ed9c0466091547fb85cab0a2ab3a0112",
            "54072df68c7740079e02ae8cddebc2f9",
            "d75cf6b2cbc74cbfb7fffe9e55adcc83",
            "a58a306faa4741d69370a341ab366662",
            "d728dbf3783a43a7accdd043c12a939d",
            "7019a84079da418eba5d0d9a55df2ea5",
            "a55451d61fc04000bac7360f04a459f1",
            "ce5ad76111884d278b190defa3498dfc",
            "c686da5af8034c90a2e73061ba83cbde",
            "f618ba09c3c547ada1d61a43c294e790",
            "41223b165d3145af96bf7b3d29991f70",
            "d94846c5ff9b4f009b8a35ba766cdc64",
            "3c5feed99fad4a01bec3640283ea93b7",
            "b700be8a0a234d3fa3ae0fcdbaa930f8",
            "b0ee610c44a6403a930c769f7909470b",
            "fb2c2353ed2a44ecb12a37ae58857fae",
            "500d065e10984466a0b60fcc5696bc2a",
            "b1caf3e0458340a0bac66f89421fddd4",
            "47d81dcbc77045188d574b0b9dd6f3cd",
            "51a7c51cfca442d7a10d427fb3b29c8e",
            "ad16c29f83e7401db0b879dd895c27fe",
            "56fb1c82b67d4cc29201285721b74d39",
            "252d17cd0fbe403e89eb63f0e49c5e91",
            "50b3a2763f3d405b8430083cc1cd5cdb",
            "ff4a0b395b0d41c795ae658716e5692e",
            "aecd69589ba94f5e9921b166b4741588",
            "7da59ddc884443e4a2d6b9098743cf1a",
            "987d52652720484182b9b47a551e09c4",
            "9c5a14a06fce4d2bbc3d471ba5258099",
            "4979d932c22e42f9bcafd089a7fbb920",
            "0e76274a94c440c2960146cf8d5b9b6e",
            "d5cadeb8a9d448eb86a79e1e459789f6",
            "a28a5ccef6404ed9a36ac51d65b842e0",
            "d9bdf9c30e284c219ebc4cdea21a3d45",
            "41833778093e4978a73c70660e1f9525",
            "2ddadf17aa0247fe909946e5f1abf093",
            "6897a68493d54b81af74090c51ec4bf2",
            "25990c531e6648a88f5ca093977655e1",
            "732270d7142f44ea87d3a41ca0227308",
            "102f9602ebfa48678b1249a74820c846",
            "963a4e8b39de46bb97b92609a7c1cc5f",
            "9e76a1d6072e4de28a86b002f99e8b71",
            "169d0cd3e91e41b095387400245e522b",
            "fb851cf352754d848dee10068236bd05",
            "cb61d9ad943142df8920035412e76fdd",
            "06b402a3399047e8a549f8f322650742",
            "7601e4ab107b4c8db408b02fe7450dc9",
            "4eaa015b421a4d199b0c091f7f604b5f",
            "9194b3b7f8e84d12a9f1ada34d5bcf75",
            "3d26a29e82454888ab5fb09d32363aaa",
            "f1e8630e4e6140908444e10a2d345765",
            "2ed0f6b7e23a4e218a4f1f01e5f17225",
            "cfe12991735643ffad24dfea9c76be24",
            "f46dffe1d71549469c052420975d5be0",
            "9e2765a57537439ca56f4b9c3b786d7f",
            "117e07ee675245e29b99895029c73ba5",
            "156f460c00204fdbb03b0865d9d01ced",
            "812a8001d5824764af0446a3e42329d4",
            "458b073db1c3496a92c3d5b93a1bdbdb",
            "87aad8cff73c43f4a3790825d60a54c9",
            "8d23e5baf89840b6b85375d9b4de18f9",
            "4b7ccef355684f6f82df45ca07f6e54b",
            "b9f880b0bb5840088c5c9670365ecc60",
            "d70443b82d4b4bbebdcc443e212b9ca7",
            "21a57574b5424d449cd4d618f4660c00",
            "9e9c5729008e4116a80d7480188a0c23",
            "c6e6a65d500e4876931e3830703c879a",
            "b76f9590e3c54cafab8b41029fc445fa",
            "d17318893a414644877792136b10462f",
            "32ab2ab3dd5b46e1b7490c21e0a88722",
            "33c0afed3db54aa5b881654f8adbf6aa",
            "80631f94bf02490e8b5bb3612423a60a",
            "52c23abce12d4af8b06d0c54c4658f50",
            "b01a9b5d14314bbc8eece903d448412a",
            "4560fb32395343799c18a13ebca8166a",
            "94896bb449894d4e8d04448bddce2c56",
            "c962ea1caa9742ca9a748d5051ece71b",
            "ce3c9da62c544d99a087bb6c0c14a540",
            "15eee86f48dd45df956268492ce2a2e2",
            "145cfdf03bd7496bbe332c3471c7546b",
            "dac85e673724480bbdfa11148e15cbb2",
            "4a7b381f2612420c9fed8d4442e093e1",
            "3ab0f4d7c0c94fbda1bd361c73abe8fe",
            "6ba90b5d31c14619a19ea13985dd4803",
            "c03f7b9a12de45d1a5c0e6b6fdeb09ed",
            "792012e9f1484d2596fed6e04e37791a",
            "e1b047ee904945caa377ef342e219f40",
            "0fe91f5398f440cda39543988fcc7c0d",
            "0f6c5e34a51e48a5a06eecc72c71abdf",
            "eb8bef4db7dd4d738c5a54ac2323f03e",
            "848c238418e84bdc85c69c4e8049988f",
            "5fe7f2223e594edcb8ff4012f4a8887e",
            "47358e12c65e4f1183ba097fd3bd400e",
            "f0d1a99421094f6e9942cb17528237e7",
            "6aad87488d6a4619a084a870a1a8a1f2",
            "cc6dcbd137fe468697bff619d50a4c70",
            "45c5bd71ec0a489f8ff9e32227ea708e",
            "30ae173be64c4d9fafca9090be21754a",
            "f4e1cd68361d4d14baae637f80a50a9b",
            "96eb1083462c4b8493cd34cb466d71c1",
            "b19743eb4bdc4e7da1a66691cac4bb26",
            "21cf162ceca94f219f02431ab24c3546",
            "d7a25046b8824fe5b7fb48f7a13f9293",
            "9c577e9a69504d6d91865544b1c399e4",
            "778b93a3fe0b4973a0c8f8ad5cc57847",
            "532c12a1356140d79b7402e928e13f9f",
            "26280bb13c2d49798b1d5331e38e4071",
            "494bb281d8d448a4b4f9eeed628f80ee",
            "3a37564d931d4d379bb18ddf5bb34025",
            "e28059f793bb4f4ebe6f247dc0256a1f",
            "7260a245b2bf4588a638c8b2da6e0c2b",
            "624a96c9b50f4c609bb1a0959360f056",
            "d7229ca8354d410bb6e5d5248e84efc2",
            "101ba0b9e7704c228d33bf56bcfd58cd",
            "de2d97a165fa40e4b190d4078103497f",
            "3f231448071548e78ce43ebc30621829",
            "393d9dca06ec40d2aa4683270b7117ec",
            "6c026f133a474ebda1ff449aa0c6aaaf",
            "245eed709665430fb64883807f6ace32",
            "4dc3685c33874c76a9d6ee9e8623287b",
            "667f4dc4491f4d8cab6d6988b47455a8",
            "f43b61d1889f40ecadc80643f21e242e",
            "d09717c31aac4cf98c08bf8e6f2b6a2d",
            "01e8acb77ff441a1942036bcb90af1b6",
            "176d14e0abf34da0b7fc918688365068",
            "95dad7ff311e4e018e25946b6acc794d",
            "683b744fc9ea4277a1dbf4c04f931cd2",
            "8d9d746f693d41b5bb1fe3efd2dc4504",
            "bc60afb6a0334b1fa6d8c39ce37e3c10",
            "3f505403a23644c1874807dca68bdca3",
            "3c68f63d879242578a0afb6170c1038b",
            "c97a246599d848faa0319c8b1ef3e35a",
            "df02fba80f0f497280d295cddb9b0ed9",
            "636f9892069a42ed852a2d0e1ab4b285",
            "92e6fbf694ff48bdab765580c56818a7",
            "b0e3ad12b4254742a3ebc85034c0c6ba",
            "734170f4a90545e094aaedb645d749d2",
            "c45e7d0251c44ab9bbcc259e6ca76677",
            "90b5ae5e0f4247bba731adc10ca481d8",
            "73b303d41428446f9917b3450781e497",
            "bba1c149af044b2b8ef2fd7d9f27e275",
            "6bec186ff2c341e9a86b92c1b76dd4da",
            "116668c02bad45a3a936b6d45bed40c3",
            "1e3a1e3347924b91820d3619ac14e176",
            "21f84507463b4b08bc9b362f7033e301",
            "81f55615894c46689fa63ceabc7e4e1b",
            "bcf6c40554a94f6fa8b01def321114b3",
            "d12b8c2d4a7c4b68b16c92dc60c36e52",
            "1e8c8ca7ede342829fe2fe52d045f9d2",
            "1bc777e902d24d2a8f1da08cf849d283",
            "5b8f8fa9035a457f8a9a779dcc18bf3d",
            "f70a1749fb0347d7b3893682726cdb0d",
            "87fd8710c21a4003b511ff0be54481bf",
            "d50f5b22c82f4ee1bcc8a0b4c640e116",
            "8c182df9ca0e4e48b80e3e451a392e7f",
            "23b517b49f424d91b34a035cd7c9d4a7",
            "c2b5e58ffa42400b91b9ae962958e431",
            "ce913926ced24339973c66c7ad4f9fef",
            "3dd1a162078e412f9782c233e9a4fb08",
            "7e405ce5829848b8a83b3bbbe636920c",
            "3da57edac05645d89da92e3eb6336e6e",
            "9565b06f013444538ac5c3edb49a691b",
            "9b2509697a0e443fa482da61067a5c83",
            "d2788fafab194a2e853fb5fda72e8b91",
            "30fa1c796a6d471699fba260597f9e79",
            "f4ac5f5f325d457abac0fd84d9fc0e28",
            "ddc74c1898c645fd9076e0c7a6c4c86f",
            "a4615025e4ad434fb08365e9f89e7328",
            "cd86fa037f89440f8b512e8f2db77a40",
            "86b45a7ea9e841e5a60d94a3d9b881bb",
            "32cd155dee9a4cca842c67abde59725c",
            "f4902a1ec16c4b47908fb5b4bb4a618e",
            "5dda8399d6f74bee951c19bf7455ccb1",
            "0d4320d5c78c4a03be1d2bb4e5e497c0",
            "8b1c14bea8d445bd84a104edbb7565c8",
            "08f51feccf7941c7bcb2cfcedf733909",
            "3c20f37ce6074bdc9378845f518f390c",
            "b47191af8c8640ccb95d4c3dc488b0f2",
            "0e303d0bac4e4be391f2ad89580b1815",
            "fffa9e1f69d741dba1cadf5829d376ff",
            "822e06fb99124fb9b48766f1798a9773",
            "06df5d6758bd4125a0e2e8d85fe7e468",
            "2e862235060440038481edfe4e546580",
            "6c38a3def1ca48459ddf4af528c0a714",
            "9b306f8ac3e240e2b5352bc5e50ce3ff",
            "120c8e06584b424a9e9912ac50978b1c",
            "83535f956c6242f994169cee51a31837",
            "2c793098ee5541b0a495ace78a4ac7a2",
            "e428e581d01247baa651fdd71a76724a",
            "672c08c7d0cc4b69b0c6ef767b62c944",
            "e060d0592d2442a0bc15916dda87cd50",
            "ed055de80c6a425fbfd5679d9291e442",
            "8d66470ea7614b60aa421d974bb280e8",
            "ea30ff49d7fa45c1b83273f6ed078577",
            "35bb6efbe06f4aab885eb1bf7f502888",
            "48cbc798d83a4664a2647e3257e4c206",
            "b63729d9ec6a45f5bba27f90dd545c80",
            "c9ed72e23eac49358c251482e8a78695",
            "5d9978ea739341b3ad584dad34f11c4a",
            "01eee0db0cfb4f209abb2732bece6783",
            "ce00148364c1439497b10053003515f7",
            "1c3979e855e54146b491d51b14102af5",
            "8d60ab67b3d64597812f5098c94bd56b",
            "e6b98a0e05994892b6ae5d9f3c86f0f6",
            "8ba4d044e2a8445cbbd4adfa0a06c992",
            "47121b3baa63442390432ce50427142a",
            "b6273ad22fe549cbbed073bc44178025",
            "74b5ef53b4764b67b4cb9de8fe33fb87",
            "422bb8699dec480eb2bd7f425fca54ca",
            "70a86a51d1ad400da39096aa7b88aaa5",
            "e5bbf314ae2d4c20a9333641dd33910c",
            "4a8a38fea5fe4c528d2964651e4fd950",
            "42a40ac57f8e4ad8aa5a3fdf254d288d",
            "9db760ebf21c4215b0726fa3ff5a75ac",
            "4d26384e0c87433d8de4c174f8f87133",
            "69fea00e7b7c43a7a237ea6358a9963b",
            "2777a15da1fe44f1a36606b19a40495a",
            "e6e42a89d5f74efab7fea9b848f1952d",
            "3cb5ccfeb36f40afa13ab952129d6d29",
            "a60e0971acc34a8c96af93ad4a0c3bf9",
            "532f8754e6c54021b409a95fd45f48c4",
            "30ab237d27344111b59c9cc2687aadd4",
            "377b49b83a6b418b9979ffa954c2f697",
            "4903e8b25b7c4bf19c3a041b8a7c705c",
            "64dd3ac71b9a487cb10975d7811aa53b",
            "76dcae1795174bd9a17995451bcae814",
            "c379717c0b0a4c6898b62066ab3d6329",
            "173b572f1eec4c44aba5aaad9d6cb541",
            "3ccef884c0cb439fa863e79609701547",
            "e9756e51d669454cb73c2fee7db0ac8e",
            "01144a5adac04f709d8816317bed2a60",
            "64a557e8d7ef420fabf3d4a47c8e3fc4",
            "3ff584243ef246a7b052fab8a8145113",
            "9b5c9b9b50f14317be586980829bdebf",
            "de1808e2c31048ab86686461b1f0076b",
            "bcff402646b7475886049e313868bf46",
            "c1ea214149f34fb7b6812ed17959418d",
            "e2c8310bb77d4d77ba9716222c8378ad",
            "daf48a260a4a47768df4273288923135",
            "b60c470640594d8ead141e09bc34f040",
            "dc9df6663db74ebc8274e4c65a7609c1",
            "06d322af77bb4f3fa44ae8ac365280f4",
            "242838d3eed74ff89258a6a1fb7fb71f",
            "a2d86672f2e44644bf02ff63319480c1",
            "e9c8d281b01e4137bfa0b769755418a0",
            "e42bca0062654bb1bcc1edbc1e8c6ded",
            "1e9cf92348c940e3a0b5f558e1e2c342",
            "ac5644060e52448194857f5461e881a3",
            "c4df133fa27943c0a15717a92a1f7c0f",
            "459e3df521774ddea6dc264675038aae",
            "f5536258c732402986f5b51c89ea9ad6",
            "f377cc08873a45a19196978019bc06ef",
            "ba501325eb7b4f5c82d4c6632e2117fc",
            "6b8d19e097bf4915b4ce0adf8169be60",
            "b8b31c08f6e04378b331c19c8881089d",
            "9b757d1a3b3c4ecbb80f24eb1d9964ed",
            "3e2105b554db4ddd8c59412e076f86ff",
            "b041b66e64424e97b6b2d9f03d1510c6",
            "cb7bf6f36bec4df3a7b5f732f308c00a",
            "4119fefffc5744989d91c247a07f0676",
            "adce4fd5bc344641a88f34df0ae95ead",
            "5dd5f439cdb244068689f1be5b170002",
            "7776d54933474db9ac077f1bd519d26c",
            "6e35f845a2a34f249ca678a06d9c8ed7",
            "3e7d49b29ec742cf9893cc1ab1b7fbe5",
            "f29e6a4413bc4a1b9ea4d65f347ebc7a",
            "7ab6f009c2dc4a3b8402287d0a522a52",
            "00ba18240bba41c2a1bf31fe8055b273",
            "ccb0121940c644d892c09495d88ad835",
            "1fe762b0790442d382ded29e27d3f3cf",
            "52cece3e17b84220a7a752ef99cd5169",
            "10606eae07904cdd8a2f77b454989eb9",
            "9fdc8317bc6348c0ad0f84b3d8c6d3d6",
            "21006b2f04314047b68ed21c84104824",
            "70282f9194dd4383b9973083dd8237e5",
            "d6dbe17d436c4c6a9226fdd12a2034df",
            "6678fefa334a4b2bb78b5a856e0a6e51",
            "f676943ea9474a05a3ead1ff84269e6a",
            "63a86ae641d1413d9a60ddabb88cbbe2",
            "1aa4298ea53d4b94a613954a1489af29",
            "50465d1d0d8f4d0bbdbab88861207a24",
            "22dd971d0fb445e1a354b52f1f45b65c",
            "9eeac317643344f8840b7bac48f4c17a",
            "b72b608aa2224f588a5eb5de8098e4f6",
            "2dc5301e97b349ec9750b07607273de5",
            "fade13d1950d469393e33a23a8a98568",
            "3b71c563d3534a0b99260d075ef25aab",
            "9699f6e3ba804c0fa8e03d18ccf7dfc1",
            "a1b7d15a84b54f1ba190afe69cc6abf9",
            "e085f42ae7524dee9631e7617d3bb2ec",
            "c4bfc43284e74ee58e88cc176445cd8e",
            "67945f99debc4e1486d6e56180f778df",
            "9de1cb9a614346cbb9d84924a878523d",
            "8e6be3db23b8417bba4830d54fea6a00",
            "c86e4a27f76543d09e3c3914a2b51028",
            "494292aab3714df78a21af015ab68e03",
            "1c02d4f457024a12b11a17e3e4cf77e6",
            "aa608e7d25bd41a38d8468a9bf5f2665",
            "378d5ab0ec214583be50a2e6705ead1d",
            "2342d923325e4da99d0911ad46231e9e",
            "3ac8cf7d338d4381b1d60370fffdb78d",
            "7302df7489054a40848b2695b3d19a4d",
            "6776c80f032d44b584f5048546df4dbf",
            "995aa3c9a2e4469f92f97c029f4073a7",
            "fcb62bb74541480ca542959fcebd306d",
            "a3919ffcf2fd401fa0b5be0cbb231680",
            "3ed180f4257042edb321f2bf84146f83",
            "2e54840eaa384e36aff4474a7186e74f",
            "7d73c7921b934bcfa989ac07ce80405d",
            "c9acc777f5084597a03cd0dd001fdcf4",
            "2d462f66479645359bebff81c3ac0e15",
            "127dea146cf34721b3522a4e5734517c",
            "3de91e81bff74a51b61aa5e8e98aeb4c",
            "4d0fbd063522438899229ad0fe6fea7f",
            "52dea09cfe9d4a84bb2ed0d6bf2f854a",
            "a831a34802c3411c949e95d693f6ddbb",
            "4eea62d576b74e34b19b6941bf250f22",
            "b8f4b998f9824dd0b93caf71b5a2c856",
            "4f92468e61644cca832f6594c28ca536",
            "48c60568952a49eda8c160949f7b5f8e",
            "86f8e63436044e388b88a1abc807527e",
            "25c54f847d204d83ba3a2084967042e3",
            "7496b39ef70c43bc803d81273ed04db2",
            "f0dbd373af184eec956a5f75cc57d34c",
            "66fc9007d4e847ab8366cc381f99cdd6",
            "9640af9438b94d349f5e2665f5ee56b0",
            "d5075007b2d04ad08e6a68aa84f0df12",
            "260b468a945c48a0871990d926aa1922",
            "793fb74ac8a14788b539a02221eb9ccf",
            "c272e9333fd54b90a2adbe249bb6a0fd",
            "f9f58ef03cab42daae0c7ab52fc15a6d",
            "b8445a76364b4f7d868c3e91ff07dfbb",
            "c5004b899e264bea96d0ae7595008f0d",
            "02ac0e2ac42546dfab498d22b5be7400",
            "87388168bfce4ac9848c82493b1e43cc",
            "06cf73868fa543d6addce08cfd85eb2b",
            "35d13462d4fc4d7996d82e120f5570e1",
            "ce4b3b3321144f668bf9987fa805540f",
            "207945b1ed574acd904d683d319bab6b",
            "62fd24e0f7ab46e8a57fa5e2d87a31d8",
            "d8deac05907d40d9b45bed62767c3ed7",
            "8d4bc88bb5084657b1f141222878d656",
            "d48ceb8116544a959e9d53071eaa7911",
            "9a1c7167a15149d1961ba97c5e8f56af",
            "357450c273cb472a8b77307e41dd5829",
            "af54bfb867dc4fabba73123316353a35",
            "af30e03b0cf245779dc9b27e9fc4887b",
            "674d04e83b714d5ebc6296fe42708254",
            "760d00f0d4fd44d79ffc0302facd877c",
            "c11a798b220b4a58ad3b68082a65366f",
            "8efeffae9c384ae49943587834a5612a",
            "c3afbb36e64a432ba66334db06bca6f9",
            "1d3d5b6d02d64de292ed7e73a1fc347c",
            "ff0d16af2cf74969ae861c83f115a997",
            "76ed27fc00774ed8a4546e257dd59c09",
            "2843f5a17d214f9aaa772876f5fa7596",
            "3eda7e1237184452881700231a88be1e",
            "4b5519eeb6cd4ac39f2151f8fa2b03b5",
            "0b709a38d74a4c8182e508de358e1e49",
            "b33e495f160f4e7f8281f20bdb49386d",
            "31e67fffe15944c8963cb3793f2964e2",
            "c76ba30f0a8c419dbe0d8bcc00e5c3ad",
            "9ab2cf38dbb549fc91dd78842abe01be",
            "90655584d3f14ec6a57306bf8ae41217",
            "0701bc9db18444de8bf385c0f2cc6b8e",
            "cc7fc5b8e67347e2b013979b50d76477",
            "43c057c33973463f9d4b53d4614a4696",
            "7f2a8021621842389ba2f38bc0c70277",
            "2ba1007d9b8248858c0bc59a35393f53",
            "31541c1b94e4484d87675868803ee188",
            "138a2d5f38ad42f4bf35b63c0a958cad",
            "57e33a1cb5194eeb881e211735b5244a",
            "1d2fa37edc7347a7b1a43d633bc9116d",
            "42bfe3dba4724117a937410958a330bf",
            "4c54255654e944ea9dd18916a38b67d1",
            "2045f0cb594e4eb3a7a1e951cdb3137b",
            "ce8255ed5f764146ac8c9b94f9c897e7",
            "284b495a36e9493a87bdbf603a4c7aa0",
            "bf3d40dfddbe4614b32e070deff775e7",
            "48748e66f85a481fb9cf1525f6f6b888",
            "76878f5591a147bdaf9cecad526a102e",
            "2c2fd22b219446909a06e2e5a39f6d3c",
            "1410184afb2b483b8c116fc333ed903a",
            "f65d55ab545e4d11bb215f36a95fd179",
            "c82845bf544b47d88f77d8540b897e46",
            "cab1afb3bb334a158175c36456969948",
            "81b8c07e90c84e3c92486c565f81f7a8",
            "7279ab9085834faaadb1584518a013fd",
            "e89963d0005d443095c0471c206c8ff5",
            "b47e9f4be9d44f5282ad1c32898c73a3",
            "e237ac4dc2904b6f9717fa6fc08d461e",
            "251b511d407f4612a20c2af7eec1dea3",
            "fc03db18e2db40fc86887c23e35bcdd5",
            "105aad33cf1c44ff92f3196af6326d11",
            "8b09e00e33344cecaebc1c89b6b30939",
            "d4f04d40c3074187853ba050d9956771",
            "074f6354d4ff49228c41ae8b4fe90f6a",
            "f970de42b6ef4ef5a30c1b6e8866e425",
            "d19c4beb79114b559a7a29d07c78fe1e",
            "6b8cc40498a044e19c06e0a87d760a54",
            "200e1d6ee70d4fa0a6188e8d4cdefa70",
            "d50ce61f5b07458dbb78b149b5e671dc",
            "c21a06f0d96d493bbc2ce7cd1fd4ae1c",
            "cd2344d98e864431afee4286b66dbdc8",
            "afd9478df9a54469bdbe0c89b61b2f31",
            "deb57f345e8e4676837efc968b36ab4b",
            "4bbbd3bc16d641bab85818cbd4fcaec0",
            "f16c709bf45f45b4a949e74e3f45756c",
            "cd2cd81c2f894c90964f39a3e43e04a1",
            "999e6f0549a2475e952633de26eef121",
            "5d12076688a94f9d9d8cd87e5630bb6f",
            "9b31389e0e574bfb8e3eb2b10835d1c9",
            "3520e87fd58940adbf7b44dedd95db4b",
            "8aa5073c225842baa733d6f8a4ff5f31",
            "93f410ad0fc84f82a5fb6bbada8d04de",
            "46db816d371848a4aa073feaf2136a75",
            "b858c3acd60749cf9e91b17722c233b3",
            "6cb6ae446caa4743a4024b8007e7ddc8",
            "1f8d9b8a69c84e06a52ff10883250fa4",
            "c9e93ac43aaf44a099933bde2b75c45e",
            "63a05d1c230f41d09e260b3321acfa14",
            "e1183639a6174d529c9fe2d3c4dc0d99",
            "790647acf8d34a92bbd34047d5331057",
            "bde399ab0e4b48c6806b5a3d138ac7a9",
            "88be63f534e4422d9f15585ec3da882b",
            "b6e3f0c359be47a4969fcf38e0d5cfc8",
            "a122690e6643478dba1d33e060f4c2cf",
            "f283db881053473e889d87aac485ae39",
            "d7b3ac35754c41cfb8293c9091cae219",
            "f6bd045b58c3448d9e576d5e74d616ef",
            "6c13362496ac4ea9bc1ed62ac261a9a1",
            "26c9093ab2354558b5ccca317b1b19dc",
            "cb5a7f43da8b4ec68d6dd4b1c8099209",
            "ee3c322bfe994fafb88d12ead828016b",
            "aa4fab91b8d149f69504b2d7ed39cc3d",
            "93bfd89bef08415ab775479aea6317bd",
            "c8058c3dad2f4d889e6f7e2abe203470",
            "2318532cb74a44c4a6ba75985b87dbdb",
            "b10f5d5055144e11918b44d2b407e02f",
            "24d69a753561469c97b310bd2c702186",
            "de720cbc1f214659b8e55b75981126bc",
            "965bbc98f53a48268758667258d69c30",
            "cb319e598790483dbadb333bdf5fd725",
            "b450ead8d92141b0add1dc9dc7005c82",
            "b774c8ceee3b45838410e9cdcc52241b",
            "825c31134258482cb3df4a8fa0fe60f9",
            "03fcbf618ee24de98fd778aded8c65d5",
            "94944b5da5064717aa9cbef6b727154e",
            "d011b532e17e42ff8c67fc3faea2d76e",
            "8123eaad6fe84bd5b2461472e0855cb9",
            "fcac7bc9d76e47f2b09aeae99712ae90",
            "2b485ca69e6f42c8bbe079c871303cef",
            "f6548af6a3564e069a094ef737d9d4db",
            "92f1b68a56a049e3ab709a1083f602b1",
            "004be3b005984651b97b1a67f9b56b53",
            "c50155a74bc848ebac760c650618e652",
            "95798b73c7c04ae8b31fde96dbffb8e5",
            "5f78ce75ef0e4984a31c64847d64befa",
            "09588829139944ba8003f16c3cdafd13",
            "181a5306ea4441d1ae5c472ccf8705ba",
            "2a644d78dcd1464391f65661c24589b4",
            "220a95c3087f41d98fd1e8575f0cf47c",
            "6b4cf9c69f694bc8872f527c49bdc60a",
            "eba0b1067a3d4eb594c4b6658e82a772",
            "387e8bb170fb48df9d3ce034b2adeb85",
            "4203bf369d0546f8a1136d7c9272fc56",
            "a01fdf8f7e2c4946af64025e48f1d2d3",
            "5dce6823f03348e68064b5e40474461c",
            "a60f9a1ec1674043a721a05992d27a17"
          ]
        },
        "collapsed": true,
        "id": "JzwLd5N6bYI7",
        "outputId": "f0ba7f7c-6f94-4ed3-8f4c-4557732c3b8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/datasets/load.py:1429: FutureWarning: The repository for google/speech_commands contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/google/speech_commands\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e2055c280b14d199a27380b4deb2f3f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11f0b3be75364b45a7175ed0e2d68e41"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/1.94G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5dd972ac68c04896b4f02a4fe7e18506"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/229M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fe365781dfc480fb1dccac14540271d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/112M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82b0d19dda964d9b960465307951250e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/84848 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2768397720fb47bab7e7ece0e0924795"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/9982 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4a14a7f7cc648d0a4582466eb261577"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/4890 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7606364fb0384ea090a5a25e4c9d271b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing dataset stats (MFCC, no masks)...\n",
            "Stats \u2014 mean=-5.8153, std=47.6515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-635936444.py:32: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 01:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d68448834be640d69712a19c385f979d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 01 \u2014 Train 17.22% (loss 3.154, F1 0.0906) | Val 18.83% (loss 3.140, F1 0.1006)\n",
            "[d128_L10] ** Saved new BEST ** (val_acc=18.83%) \u2192 checkpoints/d128_L10_best.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 02:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2726a01db194fef896157c247fccced"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 02 \u2014 Train 59.15% (loss 1.979, F1 0.4774) | Val 60.60% (loss 1.947, F1 0.4890)\n",
            "[d128_L10] ** Saved new BEST ** (val_acc=60.60%) \u2192 checkpoints/d128_L10_best.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 03:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a0c0db3ae0e436e919e1e10ad18e53e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 03 \u2014 Train 76.31% (loss 1.426, F1 0.7151) | Val 77.60% (loss 1.395, F1 0.7265)\n",
            "[d128_L10] ** Saved new BEST ** (val_acc=77.60%) \u2192 checkpoints/d128_L10_best.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 04:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82ef2f86d51447a1a2f0ca6419704705"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 04 \u2014 Train 85.51% (loss 1.141, F1 0.8203) | Val 85.98% (loss 1.124, F1 0.8247)\n",
            "[d128_L10] ** Saved new BEST ** (val_acc=85.98%) \u2192 checkpoints/d128_L10_best.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 05:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1cf9a7805b841388297b88b44b5f0f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 05 \u2014 Train 88.92% (loss 1.033, F1 0.8573) | Val 89.22% (loss 1.020, F1 0.8579)\n",
            "[d128_L10] ** Saved new BEST ** (val_acc=89.22%) \u2192 checkpoints/d128_L10_best.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 06:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50d449ba19694d0f8d2cc6e66703829b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 06 \u2014 Train 90.22% (loss 0.984, F1 0.8720) | Val 90.35% (loss 0.980, F1 0.8738)\n",
            "[d128_L10] ** Saved new BEST ** (val_acc=90.35%) \u2192 checkpoints/d128_L10_best.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 07:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4295a918d4564c028e876208d7cb86d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 07 \u2014 Train 92.44% (loss 0.917, F1 0.8949) | Val 92.69% (loss 0.907, F1 0.8963)\n",
            "[d128_L10] ** Saved new BEST ** (val_acc=92.69%) \u2192 checkpoints/d128_L10_best.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 08:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0d9299c27dd4d218cd0cc209b55ed0b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 08 \u2014 Train 92.61% (loss 0.902, F1 0.8949) | Val 92.61% (loss 0.899, F1 0.8928)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 09:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "65b96f249f384ce780814eed19a78507"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 09 \u2014 Train 92.88% (loss 0.891, F1 0.8984) | Val 93.34% (loss 0.882, F1 0.9020)\n",
            "[d128_L10] ** Saved new BEST ** (val_acc=93.34%) \u2192 checkpoints/d128_L10_best.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 10:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f394b4da4ce343dab059bc7efb5f2c0f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 10 \u2014 Train 93.42% (loss 0.875, F1 0.9039) | Val 93.31% (loss 0.878, F1 0.9023)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 11:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a47bbad07364ca596258083c3d147ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 11 \u2014 Train 93.90% (loss 0.857, F1 0.9106) | Val 93.58% (loss 0.867, F1 0.9059)\n",
            "[d128_L10] ** Saved new BEST ** (val_acc=93.58%) \u2192 checkpoints/d128_L10_best.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 12:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ed2574f6982449786781f897deda681"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 12 \u2014 Train 94.41% (loss 0.849, F1 0.9131) | Val 94.40% (loss 0.848, F1 0.9130)\n",
            "[d128_L10] ** Saved new BEST ** (val_acc=94.40%) \u2192 checkpoints/d128_L10_best.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 13:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fafb8f15851348759dfc7a5be5ff9bb8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 13 \u2014 Train 94.11% (loss 0.846, F1 0.9096) | Val 93.46% (loss 0.861, F1 0.9013)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 14:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18312bf0dca7435c82d3befb94855e25"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 14 \u2014 Train 94.69% (loss 0.833, F1 0.9182) | Val 94.63% (loss 0.835, F1 0.9168)\n",
            "[d128_L10] ** Saved new BEST ** (val_acc=94.63%) \u2192 checkpoints/d128_L10_best.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 15:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "045a6215132a4fe2849cfd7c0c0e7780"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 15 \u2014 Train 95.00% (loss 0.821, F1 0.9205) | Val 94.47% (loss 0.832, F1 0.9149)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 16:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2bd004e02c844f3aa6bc1ee2a17d0c09"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 16 \u2014 Train 95.37% (loss 0.813, F1 0.9234) | Val 94.81% (loss 0.827, F1 0.9174)\n",
            "[d128_L10] ** Saved new BEST ** (val_acc=94.81%) \u2192 checkpoints/d128_L10_best.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 17:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f288df3413b14e9b8702ddbec5a6a6e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 17 \u2014 Train 95.31% (loss 0.813, F1 0.9243) | Val 94.82% (loss 0.831, F1 0.9189)\n",
            "[d128_L10] ** Saved new BEST ** (val_acc=94.82%) \u2192 checkpoints/d128_L10_best.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 18:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd6261a60c8f4a95b15e5325e59b984e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 18 \u2014 Train 95.57% (loss 0.804, F1 0.9264) | Val 95.21% (loss 0.816, F1 0.9217)\n",
            "[d128_L10] ** Saved new BEST ** (val_acc=95.21%) \u2192 checkpoints/d128_L10_best.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 19:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f5d49b3a2b240c0b36a627bc3c81306"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 19 \u2014 Train 95.92% (loss 0.793, F1 0.9301) | Val 95.17% (loss 0.810, F1 0.9213)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 20:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ab28739a2ea498ab5b9ed63a7d3fc87"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 20 \u2014 Train 95.01% (loss 0.814, F1 0.9207) | Val 94.74% (loss 0.824, F1 0.9171)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 21:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "238b1cc16de146b3aecccdfe8edf3168"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 21 \u2014 Train 96.06% (loss 0.788, F1 0.9318) | Val 95.35% (loss 0.805, F1 0.9252)\n",
            "[d128_L10] ** Saved new BEST ** (val_acc=95.35%) \u2192 checkpoints/d128_L10_best.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 22:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b11939c9767448cbb3f2a0212c13f97"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 22 \u2014 Train 96.16% (loss 0.786, F1 0.9322) | Val 95.37% (loss 0.807, F1 0.9239)\n",
            "[d128_L10] ** Saved new BEST ** (val_acc=95.37%) \u2192 checkpoints/d128_L10_best.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 23:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "abfba0b3ece443d39e5ff80047b3533d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 23 \u2014 Train 95.94% (loss 0.791, F1 0.9313) | Val 95.11% (loss 0.813, F1 0.9224)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 24:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fdc95ec7deee4e948305136d3036f12c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 24 \u2014 Train 95.88% (loss 0.792, F1 0.9302) | Val 95.30% (loss 0.808, F1 0.9236)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 25:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47a6fde173fc4e96925301aa19299c31"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 25 \u2014 Train 96.42% (loss 0.779, F1 0.9351) | Val 95.81% (loss 0.795, F1 0.9281)\n",
            "[d128_L10] ** Saved new BEST ** (val_acc=95.81%) \u2192 checkpoints/d128_L10_best.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 26:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1aecaf77f10b4dd3aff67dcb2a186217"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 26 \u2014 Train 96.23% (loss 0.781, F1 0.9327) | Val 95.66% (loss 0.800, F1 0.9255)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 27:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67c3e74a9e404e33bc912c963703bc07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 27 \u2014 Train 96.45% (loss 0.776, F1 0.9352) | Val 95.65% (loss 0.796, F1 0.9266)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 28:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89edba936792425498b2122dd5833015"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 28 \u2014 Train 96.55% (loss 0.773, F1 0.9370) | Val 95.49% (loss 0.799, F1 0.9254)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 29:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b8c2cdae1de4c67899a42c1efd5d78a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 29 \u2014 Train 96.62% (loss 0.771, F1 0.9372) | Val 96.08% (loss 0.789, F1 0.9310)\n",
            "[d128_L10] ** Saved new BEST ** (val_acc=96.08%) \u2192 checkpoints/d128_L10_best.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 30:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82008ff5fcd8499f8c2103a181092ffd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 30 \u2014 Train 96.80% (loss 0.764, F1 0.9391) | Val 95.78% (loss 0.796, F1 0.9286)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 31:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94212f116a1245eeb85a4bf49bf09f3f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 31 \u2014 Train 96.86% (loss 0.763, F1 0.9400) | Val 95.65% (loss 0.794, F1 0.9259)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 32:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29ca4480f29e4c4dae39b826322a8e51"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 32 \u2014 Train 96.73% (loss 0.767, F1 0.9379) | Val 95.83% (loss 0.795, F1 0.9276)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 33:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc12255a021b47bb9727d573e25e0ee6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 33 \u2014 Train 96.75% (loss 0.765, F1 0.9387) | Val 95.91% (loss 0.794, F1 0.9293)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 34:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b0b4851ce4046548426a4b0691ff503"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 34 \u2014 Train 96.66% (loss 0.770, F1 0.9374) | Val 95.94% (loss 0.798, F1 0.9302)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 35:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b2cbd6a91664698aebc25cb49a44a21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 35 \u2014 Train 96.74% (loss 0.766, F1 0.9385) | Val 95.88% (loss 0.792, F1 0.9294)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 36:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6fac97e5add46678affa9763c613394"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 36 \u2014 Train 96.88% (loss 0.763, F1 0.9399) | Val 95.64% (loss 0.798, F1 0.9252)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 37:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b5c5bd244da4ce9af8afe9fd2fce2c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 37 \u2014 Train 96.80% (loss 0.764, F1 0.9390) | Val 95.69% (loss 0.798, F1 0.9273)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 38:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2bb72ce1a6374651872a1bfb093ee99e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 38 \u2014 Train 97.05% (loss 0.758, F1 0.9420) | Val 95.91% (loss 0.793, F1 0.9292)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 39:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c69cdb17afe34efc9c689f361265c1d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 39 \u2014 Train 97.12% (loss 0.755, F1 0.9422) | Val 96.06% (loss 0.788, F1 0.9313)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 40:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce5ad76111884d278b190defa3498dfc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 40 \u2014 Train 97.28% (loss 0.752, F1 0.9434) | Val 96.04% (loss 0.786, F1 0.9310)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 41:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47d81dcbc77045188d574b0b9dd6f3cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 41 \u2014 Train 97.38% (loss 0.750, F1 0.9452) | Val 96.13% (loss 0.788, F1 0.9305)\n",
            "[d128_L10] ** Saved new BEST ** (val_acc=96.13%) \u2192 checkpoints/d128_L10_best.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 42:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4979d932c22e42f9bcafd089a7fbb920"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 42 \u2014 Train 97.11% (loss 0.755, F1 0.9422) | Val 95.87% (loss 0.790, F1 0.9283)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 43:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "963a4e8b39de46bb97b92609a7c1cc5f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 43 \u2014 Train 97.18% (loss 0.753, F1 0.9434) | Val 95.85% (loss 0.790, F1 0.9293)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 44:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ed0f6b7e23a4e218a4f1f01e5f17225"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 44 \u2014 Train 97.41% (loss 0.747, F1 0.9455) | Val 95.97% (loss 0.787, F1 0.9300)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 45:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9f880b0bb5840088c5c9670365ecc60"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 45 \u2014 Train 97.19% (loss 0.752, F1 0.9435) | Val 95.85% (loss 0.790, F1 0.9280)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 46:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b01a9b5d14314bbc8eece903d448412a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 46 \u2014 Train 97.53% (loss 0.743, F1 0.9465) | Val 95.94% (loss 0.788, F1 0.9291)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 47:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c03f7b9a12de45d1a5c0e6b6fdeb09ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 47 \u2014 Train 97.15% (loss 0.752, F1 0.9429) | Val 95.78% (loss 0.797, F1 0.9276)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 48:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc6dcbd137fe468697bff619d50a4c70"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 48 \u2014 Train 97.61% (loss 0.741, F1 0.9476) | Val 96.11% (loss 0.782, F1 0.9316)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 49:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26280bb13c2d49798b1d5331e38e4071"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 49 \u2014 Train 97.61% (loss 0.740, F1 0.9474) | Val 95.72% (loss 0.794, F1 0.9262)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 50:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c026f133a474ebda1ff449aa0c6aaaf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 50 \u2014 Train 97.50% (loss 0.743, F1 0.9469) | Val 95.69% (loss 0.795, F1 0.9282)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 51:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc60afb6a0334b1fa6d8c39ce37e3c10"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 51 \u2014 Train 97.73% (loss 0.737, F1 0.9493) | Val 96.15% (loss 0.783, F1 0.9329)\n",
            "[d128_L10] ** Saved new BEST ** (val_acc=96.15%) \u2192 checkpoints/d128_L10_best.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 52:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73b303d41428446f9917b3450781e497"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 52 \u2014 Train 97.78% (loss 0.735, F1 0.9493) | Val 96.03% (loss 0.786, F1 0.9297)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 53:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b8f8fa9035a457f8a9a779dcc18bf3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 53 \u2014 Train 97.77% (loss 0.737, F1 0.9497) | Val 96.19% (loss 0.784, F1 0.9327)\n",
            "[d128_L10] ** Saved new BEST ** (val_acc=96.19%) \u2192 checkpoints/d128_L10_best.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 54:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9565b06f013444538ac5c3edb49a691b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 54 \u2014 Train 97.75% (loss 0.735, F1 0.9492) | Val 96.27% (loss 0.786, F1 0.9324)\n",
            "[d128_L10] ** Saved new BEST ** (val_acc=96.27%) \u2192 checkpoints/d128_L10_best.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 55:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5dda8399d6f74bee951c19bf7455ccb1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 55 \u2014 Train 97.97% (loss 0.730, F1 0.9509) | Val 96.40% (loss 0.779, F1 0.9334)\n",
            "[d128_L10] ** Saved new BEST ** (val_acc=96.40%) \u2192 checkpoints/d128_L10_best.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 56:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c38a3def1ca48459ddf4af528c0a714"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 56 \u2014 Train 98.00% (loss 0.730, F1 0.9518) | Val 96.07% (loss 0.783, F1 0.9314)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 57:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35bb6efbe06f4aab885eb1bf7f502888"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 57 \u2014 Train 97.99% (loss 0.728, F1 0.9515) | Val 96.14% (loss 0.788, F1 0.9308)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 58:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47121b3baa63442390432ce50427142a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 58 \u2014 Train 98.16% (loss 0.726, F1 0.9530) | Val 96.08% (loss 0.787, F1 0.9300)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 59:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2777a15da1fe44f1a36606b19a40495a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 59 \u2014 Train 97.99% (loss 0.729, F1 0.9516) | Val 96.11% (loss 0.786, F1 0.9308)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 60:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "173b572f1eec4c44aba5aaad9d6cb541"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 60 \u2014 Train 98.24% (loss 0.723, F1 0.9543) | Val 96.07% (loss 0.786, F1 0.9302)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 61:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "daf48a260a4a47768df4273288923135"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 61 \u2014 Train 98.28% (loss 0.720, F1 0.9542) | Val 96.14% (loss 0.778, F1 0.9309)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 62:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "459e3df521774ddea6dc264675038aae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 62 \u2014 Train 98.35% (loss 0.719, F1 0.9555) | Val 96.16% (loss 0.788, F1 0.9315)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 63:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "adce4fd5bc344641a88f34df0ae95ead"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 63 \u2014 Train 98.39% (loss 0.719, F1 0.9557) | Val 96.15% (loss 0.780, F1 0.9314)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 64:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10606eae07904cdd8a2f77b454989eb9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 64 \u2014 Train 98.47% (loss 0.715, F1 0.9562) | Val 96.27% (loss 0.776, F1 0.9319)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 65:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9eeac317643344f8840b7bac48f4c17a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 65 \u2014 Train 98.44% (loss 0.716, F1 0.9564) | Val 96.15% (loss 0.784, F1 0.9311)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 66:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e6be3db23b8417bba4830d54fea6a00"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 66 \u2014 Train 98.44% (loss 0.716, F1 0.9565) | Val 96.33% (loss 0.780, F1 0.9339)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 67:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fcb62bb74541480ca542959fcebd306d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 67 \u2014 Train 98.54% (loss 0.714, F1 0.9574) | Val 96.21% (loss 0.780, F1 0.9326)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 68:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a831a34802c3411c949e95d693f6ddbb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 68 \u2014 Train 98.64% (loss 0.711, F1 0.9581) | Val 96.27% (loss 0.786, F1 0.9325)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 69:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5075007b2d04ad08e6a68aa84f0df12"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 69 \u2014 Train 98.78% (loss 0.707, F1 0.9597) | Val 96.33% (loss 0.778, F1 0.9336)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 70:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce4b3b3321144f668bf9987fa805540f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 70 \u2014 Train 98.74% (loss 0.707, F1 0.9593) | Val 96.40% (loss 0.777, F1 0.9338)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 71:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "760d00f0d4fd44d79ffc0302facd877c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 71 \u2014 Train 98.79% (loss 0.706, F1 0.9596) | Val 96.24% (loss 0.782, F1 0.9313)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 72:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b33e495f160f4e7f8281f20bdb49386d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 72 \u2014 Train 98.93% (loss 0.703, F1 0.9610) | Val 96.44% (loss 0.776, F1 0.9344)\n",
            "[d128_L10] ** Saved new BEST ** (val_acc=96.44%) \u2192 checkpoints/d128_L10_best.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 73:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "138a2d5f38ad42f4bf35b63c0a958cad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 73 \u2014 Train 98.87% (loss 0.704, F1 0.9605) | Val 96.41% (loss 0.780, F1 0.9344)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 74:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c2fd22b219446909a06e2e5a39f6d3c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 74 \u2014 Train 98.90% (loss 0.702, F1 0.9611) | Val 96.56% (loss 0.773, F1 0.9352)\n",
            "[d128_L10] ** Saved new BEST ** (val_acc=96.56%) \u2192 checkpoints/d128_L10_best.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 75:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc03db18e2db40fc86887c23e35bcdd5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 75 \u2014 Train 99.04% (loss 0.699, F1 0.9623) | Val 96.57% (loss 0.776, F1 0.9355)\n",
            "[d128_L10] ** Saved new BEST ** (val_acc=96.57%) \u2192 checkpoints/d128_L10_best.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 76:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd2344d98e864431afee4286b66dbdc8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 76 \u2014 Train 99.02% (loss 0.699, F1 0.9620) | Val 96.40% (loss 0.779, F1 0.9339)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 77:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93f410ad0fc84f82a5fb6bbada8d04de"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 77 \u2014 Train 99.09% (loss 0.697, F1 0.9630) | Val 96.49% (loss 0.779, F1 0.9349)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 78:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6e3f0c359be47a4969fcf38e0d5cfc8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 78 \u2014 Train 99.04% (loss 0.699, F1 0.9627) | Val 96.30% (loss 0.782, F1 0.9332)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 79:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8058c3dad2f4d889e6f7e2abe203470"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 79 \u2014 Train 99.06% (loss 0.699, F1 0.9627) | Val 96.41% (loss 0.780, F1 0.9336)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 80:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94944b5da5064717aa9cbef6b727154e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[d128_L10] Epoch 80 \u2014 Train 99.23% (loss 0.693, F1 0.9644) | Val 96.34% (loss 0.778, F1 0.9332)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[d128_L10] Epoch 81:   0%|          | 0/663 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09588829139944ba8003f16c3cdafd13"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorboard import notebook\n",
        "\n",
        "notebook.start(\"--logdir runs\")"
      ],
      "metadata": {
        "id": "nXbrW5n9bZMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SAVE_DIR = \"/content/drive/MyDrive/kws_exports_medium\"\n",
        "!mkdir -p \"$SAVE_DIR\"\n",
        "\n",
        "# Zip folders straight to Drive paths\n",
        "!zip -qr \"$SAVE_DIR/checkpoints_expand.zip\" /content/checkpoints\n",
        "!zip -qr \"$SAVE_DIR/runs_expand.zip\"        /content/runs\n",
        "\n",
        "# Verify\n",
        "!ls -lh \"$SAVE_DIR\""
      ],
      "metadata": {
        "id": "h_qncKsC4kPM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}